name: "FPN-pva"
layer {
    name: 'input-data'
    type: 'Python'
    top: 'data'
    top: 'im_info'
    top: 'gt_boxes'
    python_param {
        module: 'roi_data_layer.layer'
        layer: 'RoIDataLayer'
        param_str: "'num_classes': 2"
    }
}

##################################################################
# convolution
##################################################################

layer {
    name: "conv1_1/conv"
    type: "Convolution"
    bottom: "data"
    top: "conv1_1/conv"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 16
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 3
        pad_w: 3
        kernel_h: 7
        kernel_w: 7
        stride_h: 2
        stride_w: 2
    }
}
layer {
    name: "conv1_1/bn"
    type: "BatchNorm"
    bottom: "conv1_1/conv"
    top: "conv1_1/conv"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv1_1/neg"
    type: "Power"
    bottom: "conv1_1/conv"
    top: "conv1_1/neg"
    power_param {
        power: 1
        scale: -1.0
        shift: 0
    }
}
layer {
    name: "conv1_1/concat"
    type: "Concat"
    bottom: "conv1_1/conv"
    bottom: "conv1_1/neg"
    top: "conv1_1"
}
layer {
    name: "conv1_1/scale"
    type: "Scale"
    bottom: "conv1_1"
    top: "conv1_1"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv1_1/relu"
    type: "ReLU"
    bottom: "conv1_1"
    top: "conv1_1"
}
layer {
    name: "pool1"
    type: "Pooling"
    bottom: "conv1_1"
    top: "pool1"
    pooling_param {
        pool: MAX
        kernel_size: 3
        stride: 2
        pad: 0
    }
}
layer {
    name: "conv2_1/1/conv"
    type: "Convolution"
    bottom: "pool1"
    top: "conv2_1/1"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 24
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv2_1/2/bn"
    type: "BatchNorm"
    bottom: "conv2_1/1"
    top: "conv2_1/2/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv2_1/2/bn_scale"
    type: "Scale"
    bottom: "conv2_1/2/pre"
    top: "conv2_1/2/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv2_1/2/relu"
    type: "ReLU"
    bottom: "conv2_1/2/pre"
    top: "conv2_1/2/pre"
}
layer {
    name: "conv2_1/2/conv"
    type: "Convolution"
    bottom: "conv2_1/2/pre"
    top: "conv2_1/2"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 24
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv2_1/3/bn"
    type: "BatchNorm"
    bottom: "conv2_1/2"
    top: "conv2_1/3/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv2_1/3/neg"
    type: "Power"
    bottom: "conv2_1/3/pre"
    top: "conv2_1/3/neg"
    power_param {
        power: 1
        scale: -1.0
        shift: 0
    }
}
layer {
    name: "conv2_1/3/concat"
    type: "Concat"
    bottom: "conv2_1/3/pre"
    bottom: "conv2_1/3/neg"
    top: "conv2_1/3/preAct"
}
layer {
    name: "conv2_1/3/scale"
    type: "Scale"
    bottom: "conv2_1/3/preAct"
    top: "conv2_1/3/preAct"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv2_1/3/relu"
    type: "ReLU"
    bottom: "conv2_1/3/preAct"
    top: "conv2_1/3/preAct"
}

layer {
    name: "conv2_1/3/conv"
    type: "Convolution"
    bottom: "conv2_1/3/preAct"
    top: "conv2_1/3"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 64
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv2_1/proj"
    type: "Convolution"
    bottom: "pool1"
    top: "conv2_1/proj"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 64
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv2_1"
    type: "Eltwise"
    bottom: "conv2_1/3"
    bottom: "conv2_1/proj"
    top: "conv2_1"
    eltwise_param {
        operation: SUM
        coeff: 1
        coeff: 1
    }
}
layer {
    name: "conv2_2/1/bn"
    type: "BatchNorm"
    bottom: "conv2_1"
    top: "conv2_2/1/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv2_2/1/bn_scale"
    type: "Scale"
    bottom: "conv2_2/1/pre"
    top: "conv2_2/1/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv2_2/1/relu"
    type: "ReLU"
    bottom: "conv2_2/1/pre"
    top: "conv2_2/1/pre"
}
layer {
    name: "conv2_2/1/conv"
    type: "Convolution"
    bottom: "conv2_2/1/pre"
    top: "conv2_2/1"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 24
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv2_2/2/bn"
    type: "BatchNorm"
    bottom: "conv2_2/1"
    top: "conv2_2/2/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv2_2/2/bn_scale"
    type: "Scale"
    bottom: "conv2_2/2/pre"
    top: "conv2_2/2/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv2_2/2/relu"
    type: "ReLU"
    bottom: "conv2_2/2/pre"
    top: "conv2_2/2/pre"
}
layer {
    name: "conv2_2/2/conv"
    type: "Convolution"
    bottom: "conv2_2/2/pre"
    top: "conv2_2/2"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 24
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv2_2/3/bn"
    type: "BatchNorm"
    bottom: "conv2_2/2"
    top: "conv2_2/3/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv2_2/3/neg"
    type: "Power"
    bottom: "conv2_2/3/pre"
    top: "conv2_2/3/neg"
    power_param {
        power: 1
        scale: -1.0
        shift: 0
    }
}
layer {
    name: "conv2_2/3/concat"
    type: "Concat"
    bottom: "conv2_2/3/pre"
    bottom: "conv2_2/3/neg"
    top: "conv2_2/3/preAct"
}
layer {
    name: "conv2_2/3/scale"
    type: "Scale"
    bottom: "conv2_2/3/preAct"
    top: "conv2_2/3/preAct"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv2_2/3/relu"
    type: "ReLU"
    bottom: "conv2_2/3/preAct"
    top: "conv2_2/3/preAct"
}
layer {
    name: "conv2_2/3/conv"
    type: "Convolution"
    bottom: "conv2_2/3/preAct"
    top: "conv2_2/3"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 64
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv2_2/input"
    type: "Power"
    bottom: "conv2_1"
    top: "conv2_2/input"
    power_param {
        power: 1
        scale: 1
        shift: 0
    }
}
layer {
    name: "conv2_2"
    type: "Eltwise"
    bottom: "conv2_2/3"
    bottom: "conv2_2/input"
    top: "conv2_2"
    eltwise_param {
        operation: SUM
        coeff: 1
        coeff: 1
    }
}
layer {
    name: "conv2_3/1/bn"
    type: "BatchNorm"
    bottom: "conv2_2"
    top: "conv2_3/1/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv2_3/1/bn_scale"
    type: "Scale"
    bottom: "conv2_3/1/pre"
    top: "conv2_3/1/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv2_3/1/relu"
    type: "ReLU"
    bottom: "conv2_3/1/pre"
    top: "conv2_3/1/pre"
}
layer {
    name: "conv2_3/1/conv"
    type: "Convolution"
    bottom: "conv2_3/1/pre"
    top: "conv2_3/1"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 24
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv2_3/2/bn"
    type: "BatchNorm"
    bottom: "conv2_3/1"
    top: "conv2_3/2/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv2_3/2/bn_scale"
    type: "Scale"
    bottom: "conv2_3/2/pre"
    top: "conv2_3/2/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv2_3/2/relu"
    type: "ReLU"
    bottom: "conv2_3/2/pre"
    top: "conv2_3/2/pre"
}
layer {
    name: "conv2_3/2/conv"
    type: "Convolution"
    bottom: "conv2_3/2/pre"
    top: "conv2_3/2"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 24
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv2_3/3/bn"
    type: "BatchNorm"
    bottom: "conv2_3/2"
    top: "conv2_3/3/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv2_3/3/neg"
    type: "Power"
    bottom: "conv2_3/3/pre"
    top: "conv2_3/3/neg"
    power_param {
        power: 1
        scale: -1.0
        shift: 0
    }
}
layer {
    name: "conv2_3/3/concat"
    type: "Concat"
    bottom: "conv2_3/3/pre"
    bottom: "conv2_3/3/neg"
    top: "conv2_3/3/preAct"
}
layer {
    name: "conv2_3/3/scale"
    type: "Scale"
    bottom: "conv2_3/3/preAct"
    top: "conv2_3/3/preAct"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv2_3/3/relu"
    type: "ReLU"
    bottom: "conv2_3/3/preAct"
    top: "conv2_3/3/preAct"
}
layer {
    name: "conv2_3/3/conv"
    type: "Convolution"
    bottom: "conv2_3/3/preAct"
    top: "conv2_3/3"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 64
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv2_3/input"
    type: "Power"
    bottom: "conv2_2"
    top: "conv2_3/input"
    power_param {
        power: 1
        scale: 1
        shift: 0
    }
}
layer {
    name: "conv2_3"
    type: "Eltwise"
    bottom: "conv2_3/3"
    bottom: "conv2_3/input"
    top: "conv2_3"
    eltwise_param {
        operation: SUM
        coeff: 1
        coeff: 1
    }
}
layer {
    name: "conv3_1/1/bn"
    type: "BatchNorm"
    bottom: "conv2_3"
    top: "conv3_1/1/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv3_1/1/bn_scale"
    type: "Scale"
    bottom: "conv3_1/1/pre"
    top: "conv3_1/1/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv3_1/1/relu"
    type: "ReLU"
    bottom: "conv3_1/1/pre"
    top: "conv3_1/1/pre"
}
layer {
    name: "conv3_1/1/conv"
    type: "Convolution"
    bottom: "conv3_1/1/pre"
    top: "conv3_1/1"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 48
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 2
        stride_w: 2
    }
}
layer {
    name: "conv3_1/2/bn"
    type: "BatchNorm"
    bottom: "conv3_1/1"
    top: "conv3_1/2/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv3_1/2/bn_scale"
    type: "Scale"
    bottom: "conv3_1/2/pre"
    top: "conv3_1/2/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv3_1/2/relu"
    type: "ReLU"
    bottom: "conv3_1/2/pre"
    top: "conv3_1/2/pre"
}
layer {
    name: "conv3_1/2/conv"
    type: "Convolution"
    bottom: "conv3_1/2/pre"
    top: "conv3_1/2"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 48
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv3_1/3/bn"
    type: "BatchNorm"
    bottom: "conv3_1/2"
    top: "conv3_1/3/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv3_1/3/neg"
    type: "Power"
    bottom: "conv3_1/3/pre"
    top: "conv3_1/3/neg"
    power_param {
        power: 1
        scale: -1.0
        shift: 0
    }
}
layer {
    name: "conv3_1/3/concat"
    type: "Concat"
    bottom: "conv3_1/3/pre"
    bottom: "conv3_1/3/neg"
    top: "conv3_1/3/preAct"
}
layer {
    name: "conv3_1/3/scale"
    type: "Scale"
    bottom: "conv3_1/3/preAct"
    top: "conv3_1/3/preAct"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv3_1/3/relu"
    type: "ReLU"
    bottom: "conv3_1/3/preAct"
    top: "conv3_1/3/preAct"
}
layer {
    name: "conv3_1/3/conv"
    type: "Convolution"
    bottom: "conv3_1/3/preAct"
    top: "conv3_1/3"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 128
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv3_1/proj"
    type: "Convolution"
    bottom: "conv3_1/1/pre"
    top: "conv3_1/proj"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 128
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 2
        stride_w: 2
    }
}
layer {
    name: "conv3_1"
    type: "Eltwise"
    bottom: "conv3_1/3"
    bottom: "conv3_1/proj"
    top: "conv3_1"
    eltwise_param {
        operation: SUM
        coeff: 1
        coeff: 1
    }
}
layer {
    name: "conv3_2/1/bn"
    type: "BatchNorm"
    bottom: "conv3_1"
    top: "conv3_2/1/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv3_2/1/bn_scale"
    type: "Scale"
    bottom: "conv3_2/1/pre"
    top: "conv3_2/1/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv3_2/1/relu"
    type: "ReLU"
    bottom: "conv3_2/1/pre"
    top: "conv3_2/1/pre"
}
layer {
    name: "conv3_2/1/conv"
    type: "Convolution"
    bottom: "conv3_2/1/pre"
    top: "conv3_2/1"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 48
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv3_2/2/bn"
    type: "BatchNorm"
    bottom: "conv3_2/1"
    top: "conv3_2/2/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv3_2/2/bn_scale"
    type: "Scale"
    bottom: "conv3_2/2/pre"
    top: "conv3_2/2/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv3_2/2/relu"
    type: "ReLU"
    bottom: "conv3_2/2/pre"
    top: "conv3_2/2/pre"
}
layer {
    name: "conv3_2/2/conv"
    type: "Convolution"
    bottom: "conv3_2/2/pre"
    top: "conv3_2/2"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 48
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv3_2/3/bn"
    type: "BatchNorm"
    bottom: "conv3_2/2"
    top: "conv3_2/3/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv3_2/3/neg"
    type: "Power"
    bottom: "conv3_2/3/pre"
    top: "conv3_2/3/neg"
    power_param {
        power: 1
        scale: -1.0
        shift: 0
    }
}
layer {
    name: "conv3_2/3/concat"
    type: "Concat"
    bottom: "conv3_2/3/pre"
    bottom: "conv3_2/3/neg"
    top: "conv3_2/3/preAct"
}
layer {
    name: "conv3_2/3/scale"
    type: "Scale"
    bottom: "conv3_2/3/preAct"
    top: "conv3_2/3/preAct"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv3_2/3/relu"
    type: "ReLU"
    bottom: "conv3_2/3/preAct"
    top: "conv3_2/3/preAct"
}
layer {
    name: "conv3_2/3/conv"
    type: "Convolution"
    bottom: "conv3_2/3/preAct"
    top: "conv3_2/3"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 128
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv3_2/input"
    type: "Power"
    bottom: "conv3_1"
    top: "conv3_2/input"
    power_param {
        power: 1
        scale: 1
        shift: 0
    }
}
layer {
    name: "conv3_2"
    type: "Eltwise"
    bottom: "conv3_2/3"
    bottom: "conv3_2/input"
    top: "conv3_2"
    eltwise_param {
        operation: SUM
        coeff: 1
        coeff: 1
    }
}
layer {
    name: "conv3_3/1/bn"
    type: "BatchNorm"
    bottom: "conv3_2"
    top: "conv3_3/1/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv3_3/1/bn_scale"
    type: "Scale"
    bottom: "conv3_3/1/pre"
    top: "conv3_3/1/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv3_3/1/relu"
    type: "ReLU"
    bottom: "conv3_3/1/pre"
    top: "conv3_3/1/pre"
}
layer {
    name: "conv3_3/1/conv"
    type: "Convolution"
    bottom: "conv3_3/1/pre"
    top: "conv3_3/1"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 48
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv3_3/2/bn"
    type: "BatchNorm"
    bottom: "conv3_3/1"
    top: "conv3_3/2/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv3_3/2/bn_scale"
    type: "Scale"
    bottom: "conv3_3/2/pre"
    top: "conv3_3/2/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv3_3/2/relu"
    type: "ReLU"
    bottom: "conv3_3/2/pre"
    top: "conv3_3/2/pre"
}
layer {
    name: "conv3_3/2/conv"
    type: "Convolution"
    bottom: "conv3_3/2/pre"
    top: "conv3_3/2"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 48
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv3_3/3/bn"
    type: "BatchNorm"
    bottom: "conv3_3/2"
    top: "conv3_3/3/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv3_3/3/neg"
    type: "Power"
    bottom: "conv3_3/3/pre"
    top: "conv3_3/3/neg"
    power_param {
        power: 1
        scale: -1.0
        shift: 0
    }
}
layer {
    name: "conv3_3/3/concat"
    type: "Concat"
    bottom: "conv3_3/3/pre"
    bottom: "conv3_3/3/neg"
    top: "conv3_3/3/preAct"
}
layer {
    name: "conv3_3/3/scale"
    type: "Scale"
    bottom: "conv3_3/3/preAct"
    top: "conv3_3/3/preAct"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv3_3/3/relu"
    type: "ReLU"
    bottom: "conv3_3/3/preAct"
    top: "conv3_3/3/preAct"
}
layer {
    name: "conv3_3/3/conv"
    type: "Convolution"
    bottom: "conv3_3/3/preAct"
    top: "conv3_3/3"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 128
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv3_3/input"
    type: "Power"
    bottom: "conv3_2"
    top: "conv3_3/input"
    power_param {
        power: 1
        scale: 1
        shift: 0
    }
}
layer {
    name: "conv3_3"
    type: "Eltwise"
    bottom: "conv3_3/3"
    bottom: "conv3_3/input"
    top: "conv3_3"
    eltwise_param {
        operation: SUM
        coeff: 1
        coeff: 1
    }
}
layer {
    name: "conv3_4/1/bn"
    type: "BatchNorm"
    bottom: "conv3_3"
    top: "conv3_4/1/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv3_4/1/bn_scale"
    type: "Scale"
    bottom: "conv3_4/1/pre"
    top: "conv3_4/1/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv3_4/1/relu"
    type: "ReLU"
    bottom: "conv3_4/1/pre"
    top: "conv3_4/1/pre"
}
layer {
    name: "conv3_4/1/conv"
    type: "Convolution"
    bottom: "conv3_4/1/pre"
    top: "conv3_4/1"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 48
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv3_4/2/bn"
    type: "BatchNorm"
    bottom: "conv3_4/1"
    top: "conv3_4/2/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv3_4/2/bn_scale"
    type: "Scale"
    bottom: "conv3_4/2/pre"
    top: "conv3_4/2/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv3_4/2/relu"
    type: "ReLU"
    bottom: "conv3_4/2/pre"
    top: "conv3_4/2/pre"
}
layer {
    name: "conv3_4/2/conv"
    type: "Convolution"
    bottom: "conv3_4/2/pre"
    top: "conv3_4/2"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 48
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv3_4/3/bn"
    type: "BatchNorm"
    bottom: "conv3_4/2"
    top: "conv3_4/3/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv3_4/3/neg"
    type: "Power"
    bottom: "conv3_4/3/pre"
    top: "conv3_4/3/neg"
    power_param {
        power: 1
        scale: -1.0
        shift: 0
    }
}
layer {
    name: "conv3_4/3/concat"
    type: "Concat"
    bottom: "conv3_4/3/pre"
    bottom: "conv3_4/3/neg"
    top: "conv3_4/3/preAct"
}
layer {
    name: "conv3_4/3/scale"
    type: "Scale"
    bottom: "conv3_4/3/preAct"
    top: "conv3_4/3/preAct"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv3_4/3/relu"
    type: "ReLU"
    bottom: "conv3_4/3/preAct"
    top: "conv3_4/3/preAct"
}
layer {
    name: "conv3_4/3/conv"
    type: "Convolution"
    bottom: "conv3_4/3/preAct"
    top: "conv3_4/3"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 128
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv3_4/input"
    type: "Power"
    bottom: "conv3_3"
    top: "conv3_4/input"
    power_param {
        power: 1
        scale: 1
        shift: 0
    }
}
layer {
    name: "conv3_4"
    type: "Eltwise"
    bottom: "conv3_4/3"
    bottom: "conv3_4/input"
    top: "conv3_4"
    eltwise_param {
        operation: SUM
        coeff: 1
        coeff: 1
    }
}
layer {
    name: "conv4_1/incep/bn"
    type: "BatchNorm"
    bottom: "conv3_4"
    top: "conv4_1/incep/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_1/incep/bn_scale"
    type: "Scale"
    bottom: "conv4_1/incep/pre"
    top: "conv4_1/incep/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_1/incep/relu"
    type: "ReLU"
    bottom: "conv4_1/incep/pre"
    top: "conv4_1/incep/pre"
}
layer {
    name: "conv4_1/incep/0/conv"
    type: "Convolution"
    bottom: "conv4_1/incep/pre"
    top: "conv4_1/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 2
        stride_w: 2
    }
}
layer {
    name: "conv4_1/incep/0/bn"
    type: "BatchNorm"
    bottom: "conv4_1/incep/0"
    top: "conv4_1/incep/0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_1/incep/0/bn_scale"
    type: "Scale"
    bottom: "conv4_1/incep/0"
    top: "conv4_1/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_1/incep/0/relu"
    type: "ReLU"
    bottom: "conv4_1/incep/0"
    top: "conv4_1/incep/0"
}
layer {
    name: "conv4_1/incep/1_reduce/conv"
    type: "Convolution"
    bottom: "conv4_1/incep/pre"
    top: "conv4_1/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 48
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 2
        stride_w: 2
    }
}
layer {
    name: "conv4_1/incep/1_reduce/bn"
    type: "BatchNorm"
    bottom: "conv4_1/incep/1_reduce"
    top: "conv4_1/incep/1_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_1/incep/1_reduce/bn_scale"
    type: "Scale"
    bottom: "conv4_1/incep/1_reduce"
    top: "conv4_1/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_1/incep/1_reduce/relu"
    type: "ReLU"
    bottom: "conv4_1/incep/1_reduce"
    top: "conv4_1/incep/1_reduce"
}
layer {
    name: "conv4_1/incep/1_0/conv"
    type: "Convolution"
    bottom: "conv4_1/incep/1_reduce"
    top: "conv4_1/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 128
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_1/incep/1_0/bn"
    type: "BatchNorm"
    bottom: "conv4_1/incep/1_0"
    top: "conv4_1/incep/1_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_1/incep/1_0/bn_scale"
    type: "Scale"
    bottom: "conv4_1/incep/1_0"
    top: "conv4_1/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_1/incep/1_0/relu"
    type: "ReLU"
    bottom: "conv4_1/incep/1_0"
    top: "conv4_1/incep/1_0"
}
layer {
    name: "conv4_1/incep/2_reduce/conv"
    type: "Convolution"
    bottom: "conv4_1/incep/pre"
    top: "conv4_1/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 24
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 2
        stride_w: 2
    }
}
layer {
    name: "conv4_1/incep/2_reduce/bn"
    type: "BatchNorm"
    bottom: "conv4_1/incep/2_reduce"
    top: "conv4_1/incep/2_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_1/incep/2_reduce/bn_scale"
    type: "Scale"
    bottom: "conv4_1/incep/2_reduce"
    top: "conv4_1/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_1/incep/2_reduce/relu"
    type: "ReLU"
    bottom: "conv4_1/incep/2_reduce"
    top: "conv4_1/incep/2_reduce"
}
layer {
    name: "conv4_1/incep/2_0/conv"
    type: "Convolution"
    bottom: "conv4_1/incep/2_reduce"
    top: "conv4_1/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 48
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_1/incep/2_0/bn"
    type: "BatchNorm"
    bottom: "conv4_1/incep/2_0"
    top: "conv4_1/incep/2_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_1/incep/2_0/bn_scale"
    type: "Scale"
    bottom: "conv4_1/incep/2_0"
    top: "conv4_1/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_1/incep/2_0/relu"
    type: "ReLU"
    bottom: "conv4_1/incep/2_0"
    top: "conv4_1/incep/2_0"
}
layer {
    name: "conv4_1/incep/2_1/conv"
    type: "Convolution"
    bottom: "conv4_1/incep/2_0"
    top: "conv4_1/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 48
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_1/incep/2_1/bn"
    type: "BatchNorm"
    bottom: "conv4_1/incep/2_1"
    top: "conv4_1/incep/2_1"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_1/incep/2_1/bn_scale"
    type: "Scale"
    bottom: "conv4_1/incep/2_1"
    top: "conv4_1/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_1/incep/2_1/relu"
    type: "ReLU"
    bottom: "conv4_1/incep/2_1"
    top: "conv4_1/incep/2_1"
}
layer {
    name: "conv4_1/incep/pool"
    type: "Pooling"
    bottom: "conv4_1/incep/pre"
    top: "conv4_1/incep/pool"
    pooling_param {
        pool: MAX
        kernel_size: 3
        stride: 2
        pad: 0
    }
}
layer {
    name: "conv4_1/incep/poolproj/conv"
    type: "Convolution"
    bottom: "conv4_1/incep/pool"
    top: "conv4_1/incep/poolproj"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 128
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_1/incep/poolproj/bn"
    type: "BatchNorm"
    bottom: "conv4_1/incep/poolproj"
    top: "conv4_1/incep/poolproj"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_1/incep/poolproj/bn_scale"
    type: "Scale"
    bottom: "conv4_1/incep/poolproj"
    top: "conv4_1/incep/poolproj"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_1/incep/poolproj/relu"
    type: "ReLU"
    bottom: "conv4_1/incep/poolproj"
    top: "conv4_1/incep/poolproj"
}
layer {
    name: "conv4_1/incep"
    type: "Concat"
    bottom: "conv4_1/incep/0"
    bottom: "conv4_1/incep/1_0"
    bottom: "conv4_1/incep/2_1"
    bottom: "conv4_1/incep/poolproj"
    top: "conv4_1/incep"
}
layer {
    name: "conv4_1/out/conv"
    type: "Convolution"
    bottom: "conv4_1/incep"
    top: "conv4_1/out"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 256
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_1/proj"
    type: "Convolution"
    bottom: "conv3_4"
    top: "conv4_1/proj"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 256
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 2
        stride_w: 2
    }
}
layer {
    name: "conv4_1"
    type: "Eltwise"
    bottom: "conv4_1/out"
    bottom: "conv4_1/proj"
    top: "conv4_1"
    eltwise_param {
        operation: SUM
        coeff: 1
        coeff: 1
    }
}
layer {
    name: "conv4_2/incep/bn"
    type: "BatchNorm"
    bottom: "conv4_1"
    top: "conv4_2/incep/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_2/incep/bn_scale"
    type: "Scale"
    bottom: "conv4_2/incep/pre"
    top: "conv4_2/incep/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_2/incep/relu"
    type: "ReLU"
    bottom: "conv4_2/incep/pre"
    top: "conv4_2/incep/pre"
}
layer {
    name: "conv4_2/incep/0/conv"
    type: "Convolution"
    bottom: "conv4_2/incep/pre"
    top: "conv4_2/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_2/incep/0/bn"
    type: "BatchNorm"
    bottom: "conv4_2/incep/0"
    top: "conv4_2/incep/0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_2/incep/0/bn_scale"
    type: "Scale"
    bottom: "conv4_2/incep/0"
    top: "conv4_2/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_2/incep/0/relu"
    type: "ReLU"
    bottom: "conv4_2/incep/0"
    top: "conv4_2/incep/0"
}
layer {
    name: "conv4_2/incep/1_reduce/conv"
    type: "Convolution"
    bottom: "conv4_2/incep/pre"
    top: "conv4_2/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_2/incep/1_reduce/bn"
    type: "BatchNorm"
    bottom: "conv4_2/incep/1_reduce"
    top: "conv4_2/incep/1_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_2/incep/1_reduce/bn_scale"
    type: "Scale"
    bottom: "conv4_2/incep/1_reduce"
    top: "conv4_2/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_2/incep/1_reduce/relu"
    type: "ReLU"
    bottom: "conv4_2/incep/1_reduce"
    top: "conv4_2/incep/1_reduce"
}
layer {
    name: "conv4_2/incep/1_0/conv"
    type: "Convolution"
    bottom: "conv4_2/incep/1_reduce"
    top: "conv4_2/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 128
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_2/incep/1_0/bn"
    type: "BatchNorm"
    bottom: "conv4_2/incep/1_0"
    top: "conv4_2/incep/1_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_2/incep/1_0/bn_scale"
    type: "Scale"
    bottom: "conv4_2/incep/1_0"
    top: "conv4_2/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_2/incep/1_0/relu"
    type: "ReLU"
    bottom: "conv4_2/incep/1_0"
    top: "conv4_2/incep/1_0"
}
layer {
    name: "conv4_2/incep/2_reduce/conv"
    type: "Convolution"
    bottom: "conv4_2/incep/pre"
    top: "conv4_2/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 24
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_2/incep/2_reduce/bn"
    type: "BatchNorm"
    bottom: "conv4_2/incep/2_reduce"
    top: "conv4_2/incep/2_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_2/incep/2_reduce/bn_scale"
    type: "Scale"
    bottom: "conv4_2/incep/2_reduce"
    top: "conv4_2/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_2/incep/2_reduce/relu"
    type: "ReLU"
    bottom: "conv4_2/incep/2_reduce"
    top: "conv4_2/incep/2_reduce"
}
layer {
    name: "conv4_2/incep/2_0/conv"
    type: "Convolution"
    bottom: "conv4_2/incep/2_reduce"
    top: "conv4_2/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 48
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_2/incep/2_0/bn"
    type: "BatchNorm"
    bottom: "conv4_2/incep/2_0"
    top: "conv4_2/incep/2_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_2/incep/2_0/bn_scale"
    type: "Scale"
    bottom: "conv4_2/incep/2_0"
    top: "conv4_2/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_2/incep/2_0/relu"
    type: "ReLU"
    bottom: "conv4_2/incep/2_0"
    top: "conv4_2/incep/2_0"
}
layer {
    name: "conv4_2/incep/2_1/conv"
    type: "Convolution"
    bottom: "conv4_2/incep/2_0"
    top: "conv4_2/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 48
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_2/incep/2_1/bn"
    type: "BatchNorm"
    bottom: "conv4_2/incep/2_1"
    top: "conv4_2/incep/2_1"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_2/incep/2_1/bn_scale"
    type: "Scale"
    bottom: "conv4_2/incep/2_1"
    top: "conv4_2/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_2/incep/2_1/relu"
    type: "ReLU"
    bottom: "conv4_2/incep/2_1"
    top: "conv4_2/incep/2_1"
}
layer {
    name: "conv4_2/incep"
    type: "Concat"
    bottom: "conv4_2/incep/0"
    bottom: "conv4_2/incep/1_0"
    bottom: "conv4_2/incep/2_1"
    top: "conv4_2/incep"
}
layer {
    name: "conv4_2/out/conv"
    type: "Convolution"
    bottom: "conv4_2/incep"
    top: "conv4_2/out"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 256
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_2/input"
    type: "Power"
    bottom: "conv4_1"
    top: "conv4_2/input"
    power_param {
        power: 1
        scale: 1
        shift: 0
    }
}
layer {
    name: "conv4_2"
    type: "Eltwise"
    bottom: "conv4_2/out"
    bottom: "conv4_2/input"
    top: "conv4_2"
    eltwise_param {
        operation: SUM
        coeff: 1
        coeff: 1
    }
}
layer {
    name: "conv4_3/incep/bn"
    type: "BatchNorm"
    bottom: "conv4_2"
    top: "conv4_3/incep/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_3/incep/bn_scale"
    type: "Scale"
    bottom: "conv4_3/incep/pre"
    top: "conv4_3/incep/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_3/incep/relu"
    type: "ReLU"
    bottom: "conv4_3/incep/pre"
    top: "conv4_3/incep/pre"
}
layer {
    name: "conv4_3/incep/0/conv"
    type: "Convolution"
    bottom: "conv4_3/incep/pre"
    top: "conv4_3/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_3/incep/0/bn"
    type: "BatchNorm"
    bottom: "conv4_3/incep/0"
    top: "conv4_3/incep/0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_3/incep/0/bn_scale"
    type: "Scale"
    bottom: "conv4_3/incep/0"
    top: "conv4_3/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_3/incep/0/relu"
    type: "ReLU"
    bottom: "conv4_3/incep/0"
    top: "conv4_3/incep/0"
}
layer {
    name: "conv4_3/incep/1_reduce/conv"
    type: "Convolution"
    bottom: "conv4_3/incep/pre"
    top: "conv4_3/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_3/incep/1_reduce/bn"
    type: "BatchNorm"
    bottom: "conv4_3/incep/1_reduce"
    top: "conv4_3/incep/1_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_3/incep/1_reduce/bn_scale"
    type: "Scale"
    bottom: "conv4_3/incep/1_reduce"
    top: "conv4_3/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_3/incep/1_reduce/relu"
    type: "ReLU"
    bottom: "conv4_3/incep/1_reduce"
    top: "conv4_3/incep/1_reduce"
}
layer {
    name: "conv4_3/incep/1_0/conv"
    type: "Convolution"
    bottom: "conv4_3/incep/1_reduce"
    top: "conv4_3/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 128
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_3/incep/1_0/bn"
    type: "BatchNorm"
    bottom: "conv4_3/incep/1_0"
    top: "conv4_3/incep/1_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_3/incep/1_0/bn_scale"
    type: "Scale"
    bottom: "conv4_3/incep/1_0"
    top: "conv4_3/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_3/incep/1_0/relu"
    type: "ReLU"
    bottom: "conv4_3/incep/1_0"
    top: "conv4_3/incep/1_0"
}
layer {
    name: "conv4_3/incep/2_reduce/conv"
    type: "Convolution"
    bottom: "conv4_3/incep/pre"
    top: "conv4_3/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 24
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_3/incep/2_reduce/bn"
    type: "BatchNorm"
    bottom: "conv4_3/incep/2_reduce"
    top: "conv4_3/incep/2_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_3/incep/2_reduce/bn_scale"
    type: "Scale"
    bottom: "conv4_3/incep/2_reduce"
    top: "conv4_3/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_3/incep/2_reduce/relu"
    type: "ReLU"
    bottom: "conv4_3/incep/2_reduce"
    top: "conv4_3/incep/2_reduce"
}
layer {
    name: "conv4_3/incep/2_0/conv"
    type: "Convolution"
    bottom: "conv4_3/incep/2_reduce"
    top: "conv4_3/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 48
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_3/incep/2_0/bn"
    type: "BatchNorm"
    bottom: "conv4_3/incep/2_0"
    top: "conv4_3/incep/2_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_3/incep/2_0/bn_scale"
    type: "Scale"
    bottom: "conv4_3/incep/2_0"
    top: "conv4_3/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_3/incep/2_0/relu"
    type: "ReLU"
    bottom: "conv4_3/incep/2_0"
    top: "conv4_3/incep/2_0"
}
layer {
    name: "conv4_3/incep/2_1/conv"
    type: "Convolution"
    bottom: "conv4_3/incep/2_0"
    top: "conv4_3/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 48
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_3/incep/2_1/bn"
    type: "BatchNorm"
    bottom: "conv4_3/incep/2_1"
    top: "conv4_3/incep/2_1"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_3/incep/2_1/bn_scale"
    type: "Scale"
    bottom: "conv4_3/incep/2_1"
    top: "conv4_3/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_3/incep/2_1/relu"
    type: "ReLU"
    bottom: "conv4_3/incep/2_1"
    top: "conv4_3/incep/2_1"
}
layer {
    name: "conv4_3/incep"
    type: "Concat"
    bottom: "conv4_3/incep/0"
    bottom: "conv4_3/incep/1_0"
    bottom: "conv4_3/incep/2_1"
    top: "conv4_3/incep"
}
layer {
    name: "conv4_3/out/conv"
    type: "Convolution"
    bottom: "conv4_3/incep"
    top: "conv4_3/out"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 256
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_3/input"
    type: "Power"
    bottom: "conv4_2"
    top: "conv4_3/input"
    power_param {
        power: 1
        scale: 1
        shift: 0
    }
}
layer {
    name: "conv4_3"
    type: "Eltwise"
    bottom: "conv4_3/out"
    bottom: "conv4_3/input"
    top: "conv4_3"
    eltwise_param {
        operation: SUM
        coeff: 1
        coeff: 1
    }
}
layer {
    name: "conv4_4/incep/bn"
    type: "BatchNorm"
    bottom: "conv4_3"
    top: "conv4_4/incep/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_4/incep/bn_scale"
    type: "Scale"
    bottom: "conv4_4/incep/pre"
    top: "conv4_4/incep/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_4/incep/relu"
    type: "ReLU"
    bottom: "conv4_4/incep/pre"
    top: "conv4_4/incep/pre"
}
layer {
    name: "conv4_4/incep/0/conv"
    type: "Convolution"
    bottom: "conv4_4/incep/pre"
    top: "conv4_4/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_4/incep/0/bn"
    type: "BatchNorm"
    bottom: "conv4_4/incep/0"
    top: "conv4_4/incep/0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_4/incep/0/bn_scale"
    type: "Scale"
    bottom: "conv4_4/incep/0"
    top: "conv4_4/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_4/incep/0/relu"
    type: "ReLU"
    bottom: "conv4_4/incep/0"
    top: "conv4_4/incep/0"
}
layer {
    name: "conv4_4/incep/1_reduce/conv"
    type: "Convolution"
    bottom: "conv4_4/incep/pre"
    top: "conv4_4/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_4/incep/1_reduce/bn"
    type: "BatchNorm"
    bottom: "conv4_4/incep/1_reduce"
    top: "conv4_4/incep/1_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_4/incep/1_reduce/bn_scale"
    type: "Scale"
    bottom: "conv4_4/incep/1_reduce"
    top: "conv4_4/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_4/incep/1_reduce/relu"
    type: "ReLU"
    bottom: "conv4_4/incep/1_reduce"
    top: "conv4_4/incep/1_reduce"
}
layer {
    name: "conv4_4/incep/1_0/conv"
    type: "Convolution"
    bottom: "conv4_4/incep/1_reduce"
    top: "conv4_4/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 128
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_4/incep/1_0/bn"
    type: "BatchNorm"
    bottom: "conv4_4/incep/1_0"
    top: "conv4_4/incep/1_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_4/incep/1_0/bn_scale"
    type: "Scale"
    bottom: "conv4_4/incep/1_0"
    top: "conv4_4/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_4/incep/1_0/relu"
    type: "ReLU"
    bottom: "conv4_4/incep/1_0"
    top: "conv4_4/incep/1_0"
}
layer {
    name: "conv4_4/incep/2_reduce/conv"
    type: "Convolution"
    bottom: "conv4_4/incep/pre"
    top: "conv4_4/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 24
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_4/incep/2_reduce/bn"
    type: "BatchNorm"
    bottom: "conv4_4/incep/2_reduce"
    top: "conv4_4/incep/2_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_4/incep/2_reduce/bn_scale"
    type: "Scale"
    bottom: "conv4_4/incep/2_reduce"
    top: "conv4_4/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_4/incep/2_reduce/relu"
    type: "ReLU"
    bottom: "conv4_4/incep/2_reduce"
    top: "conv4_4/incep/2_reduce"
}
layer {
    name: "conv4_4/incep/2_0/conv"
    type: "Convolution"
    bottom: "conv4_4/incep/2_reduce"
    top: "conv4_4/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 48
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_4/incep/2_0/bn"
    type: "BatchNorm"
    bottom: "conv4_4/incep/2_0"
    top: "conv4_4/incep/2_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_4/incep/2_0/bn_scale"
    type: "Scale"
    bottom: "conv4_4/incep/2_0"
    top: "conv4_4/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_4/incep/2_0/relu"
    type: "ReLU"
    bottom: "conv4_4/incep/2_0"
    top: "conv4_4/incep/2_0"
}
layer {
    name: "conv4_4/incep/2_1/conv"
    type: "Convolution"
    bottom: "conv4_4/incep/2_0"
    top: "conv4_4/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 48
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_4/incep/2_1/bn"
    type: "BatchNorm"
    bottom: "conv4_4/incep/2_1"
    top: "conv4_4/incep/2_1"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv4_4/incep/2_1/bn_scale"
    type: "Scale"
    bottom: "conv4_4/incep/2_1"
    top: "conv4_4/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4_4/incep/2_1/relu"
    type: "ReLU"
    bottom: "conv4_4/incep/2_1"
    top: "conv4_4/incep/2_1"
}
layer {
    name: "conv4_4/incep"
    type: "Concat"
    bottom: "conv4_4/incep/0"
    bottom: "conv4_4/incep/1_0"
    bottom: "conv4_4/incep/2_1"
    top: "conv4_4/incep"
}
layer {
    name: "conv4_4/out/conv"
    type: "Convolution"
    bottom: "conv4_4/incep"
    top: "conv4_4/out"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 256
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv4_4/input"
    type: "Power"
    bottom: "conv4_3"
    top: "conv4_4/input"
    power_param {
        power: 1
        scale: 1
        shift: 0
    }
}
layer {
    name: "conv4_4"
    type: "Eltwise"
    bottom: "conv4_4/out"
    bottom: "conv4_4/input"
    top: "conv4_4"
    eltwise_param {
        operation: SUM
        coeff: 1
        coeff: 1
    }
}
layer {
    name: "conv5_1/incep/bn"
    type: "BatchNorm"
    bottom: "conv4_4"
    top: "conv5_1/incep/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_1/incep/bn_scale"
    type: "Scale"
    bottom: "conv5_1/incep/pre"
    top: "conv5_1/incep/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_1/incep/relu"
    type: "ReLU"
    bottom: "conv5_1/incep/pre"
    top: "conv5_1/incep/pre"
}
layer {
    name: "conv5_1/incep/0/conv"
    type: "Convolution"
    bottom: "conv5_1/incep/pre"
    top: "conv5_1/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 2
        stride_w: 2
    }
}
layer {
    name: "conv5_1/incep/0/bn"
    type: "BatchNorm"
    bottom: "conv5_1/incep/0"
    top: "conv5_1/incep/0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_1/incep/0/bn_scale"
    type: "Scale"
    bottom: "conv5_1/incep/0"
    top: "conv5_1/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_1/incep/0/relu"
    type: "ReLU"
    bottom: "conv5_1/incep/0"
    top: "conv5_1/incep/0"
}
layer {
    name: "conv5_1/incep/1_reduce/conv"
    type: "Convolution"
    bottom: "conv5_1/incep/pre"
    top: "conv5_1/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 96
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 2
        stride_w: 2
    }
}
layer {
    name: "conv5_1/incep/1_reduce/bn"
    type: "BatchNorm"
    bottom: "conv5_1/incep/1_reduce"
    top: "conv5_1/incep/1_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_1/incep/1_reduce/bn_scale"
    type: "Scale"
    bottom: "conv5_1/incep/1_reduce"
    top: "conv5_1/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_1/incep/1_reduce/relu"
    type: "ReLU"
    bottom: "conv5_1/incep/1_reduce"
    top: "conv5_1/incep/1_reduce"
}
layer {
    name: "conv5_1/incep/1_0/conv"
    type: "Convolution"
    bottom: "conv5_1/incep/1_reduce"
    top: "conv5_1/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 192
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_1/incep/1_0/bn"
    type: "BatchNorm"
    bottom: "conv5_1/incep/1_0"
    top: "conv5_1/incep/1_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_1/incep/1_0/bn_scale"
    type: "Scale"
    bottom: "conv5_1/incep/1_0"
    top: "conv5_1/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_1/incep/1_0/relu"
    type: "ReLU"
    bottom: "conv5_1/incep/1_0"
    top: "conv5_1/incep/1_0"
}
layer {
    name: "conv5_1/incep/2_reduce/conv"
    type: "Convolution"
    bottom: "conv5_1/incep/pre"
    top: "conv5_1/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 32
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 2
        stride_w: 2
    }
}
layer {
    name: "conv5_1/incep/2_reduce/bn"
    type: "BatchNorm"
    bottom: "conv5_1/incep/2_reduce"
    top: "conv5_1/incep/2_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_1/incep/2_reduce/bn_scale"
    type: "Scale"
    bottom: "conv5_1/incep/2_reduce"
    top: "conv5_1/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_1/incep/2_reduce/relu"
    type: "ReLU"
    bottom: "conv5_1/incep/2_reduce"
    top: "conv5_1/incep/2_reduce"
}
layer {
    name: "conv5_1/incep/2_0/conv"
    type: "Convolution"
    bottom: "conv5_1/incep/2_reduce"
    top: "conv5_1/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_1/incep/2_0/bn"
    type: "BatchNorm"
    bottom: "conv5_1/incep/2_0"
    top: "conv5_1/incep/2_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_1/incep/2_0/bn_scale"
    type: "Scale"
    bottom: "conv5_1/incep/2_0"
    top: "conv5_1/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_1/incep/2_0/relu"
    type: "ReLU"
    bottom: "conv5_1/incep/2_0"
    top: "conv5_1/incep/2_0"
}
layer {
    name: "conv5_1/incep/2_1/conv"
    type: "Convolution"
    bottom: "conv5_1/incep/2_0"
    top: "conv5_1/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_1/incep/2_1/bn"
    type: "BatchNorm"
    bottom: "conv5_1/incep/2_1"
    top: "conv5_1/incep/2_1"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_1/incep/2_1/bn_scale"
    type: "Scale"
    bottom: "conv5_1/incep/2_1"
    top: "conv5_1/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_1/incep/2_1/relu"
    type: "ReLU"
    bottom: "conv5_1/incep/2_1"
    top: "conv5_1/incep/2_1"
}
layer {
    name: "conv5_1/incep/pool"
    type: "Pooling"
    bottom: "conv5_1/incep/pre"
    top: "conv5_1/incep/pool"
    pooling_param {
        pool: MAX
        kernel_size: 3
        stride: 2
        pad: 0
    }
}
layer {
    name: "conv5_1/incep/poolproj/conv"
    type: "Convolution"
    bottom: "conv5_1/incep/pool"
    top: "conv5_1/incep/poolproj"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 128
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_1/incep/poolproj/bn"
    type: "BatchNorm"
    bottom: "conv5_1/incep/poolproj"
    top: "conv5_1/incep/poolproj"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_1/incep/poolproj/bn_scale"
    type: "Scale"
    bottom: "conv5_1/incep/poolproj"
    top: "conv5_1/incep/poolproj"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_1/incep/poolproj/relu"
    type: "ReLU"
    bottom: "conv5_1/incep/poolproj"
    top: "conv5_1/incep/poolproj"
}
layer {
    name: "conv5_1/incep"
    type: "Concat"
    bottom: "conv5_1/incep/0"
    bottom: "conv5_1/incep/1_0"
    bottom: "conv5_1/incep/2_1"
    bottom: "conv5_1/incep/poolproj"
    top: "conv5_1/incep"
}
layer {
    name: "conv5_1/out/conv"
    type: "Convolution"
    bottom: "conv5_1/incep"
    top: "conv5_1/out"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 384
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_1/proj"
    type: "Convolution"
    bottom: "conv4_4"
    top: "conv5_1/proj"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 384
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 2
        stride_w: 2
    }
}
layer {
    name: "conv5_1"
    type: "Eltwise"
    bottom: "conv5_1/out"
    bottom: "conv5_1/proj"
    top: "conv5_1"
    eltwise_param {
        operation: SUM
        coeff: 1
        coeff: 1
    }
}
layer {
    name: "conv5_2/incep/bn"
    type: "BatchNorm"
    bottom: "conv5_1"
    top: "conv5_2/incep/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_2/incep/bn_scale"
    type: "Scale"
    bottom: "conv5_2/incep/pre"
    top: "conv5_2/incep/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_2/incep/relu"
    type: "ReLU"
    bottom: "conv5_2/incep/pre"
    top: "conv5_2/incep/pre"
}
layer {
    name: "conv5_2/incep/0/conv"
    type: "Convolution"
    bottom: "conv5_2/incep/pre"
    top: "conv5_2/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_2/incep/0/bn"
    type: "BatchNorm"
    bottom: "conv5_2/incep/0"
    top: "conv5_2/incep/0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_2/incep/0/bn_scale"
    type: "Scale"
    bottom: "conv5_2/incep/0"
    top: "conv5_2/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_2/incep/0/relu"
    type: "ReLU"
    bottom: "conv5_2/incep/0"
    top: "conv5_2/incep/0"
}
layer {
    name: "conv5_2/incep/1_reduce/conv"
    type: "Convolution"
    bottom: "conv5_2/incep/pre"
    top: "conv5_2/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 96
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_2/incep/1_reduce/bn"
    type: "BatchNorm"
    bottom: "conv5_2/incep/1_reduce"
    top: "conv5_2/incep/1_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_2/incep/1_reduce/bn_scale"
    type: "Scale"
    bottom: "conv5_2/incep/1_reduce"
    top: "conv5_2/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_2/incep/1_reduce/relu"
    type: "ReLU"
    bottom: "conv5_2/incep/1_reduce"
    top: "conv5_2/incep/1_reduce"
}
layer {
    name: "conv5_2/incep/1_0/conv"
    type: "Convolution"
    bottom: "conv5_2/incep/1_reduce"
    top: "conv5_2/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 192
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_2/incep/1_0/bn"
    type: "BatchNorm"
    bottom: "conv5_2/incep/1_0"
    top: "conv5_2/incep/1_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_2/incep/1_0/bn_scale"
    type: "Scale"
    bottom: "conv5_2/incep/1_0"
    top: "conv5_2/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_2/incep/1_0/relu"
    type: "ReLU"
    bottom: "conv5_2/incep/1_0"
    top: "conv5_2/incep/1_0"
}
layer {
    name: "conv5_2/incep/2_reduce/conv"
    type: "Convolution"
    bottom: "conv5_2/incep/pre"
    top: "conv5_2/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 32
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_2/incep/2_reduce/bn"
    type: "BatchNorm"
    bottom: "conv5_2/incep/2_reduce"
    top: "conv5_2/incep/2_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_2/incep/2_reduce/bn_scale"
    type: "Scale"
    bottom: "conv5_2/incep/2_reduce"
    top: "conv5_2/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_2/incep/2_reduce/relu"
    type: "ReLU"
    bottom: "conv5_2/incep/2_reduce"
    top: "conv5_2/incep/2_reduce"
}
layer {
    name: "conv5_2/incep/2_0/conv"
    type: "Convolution"
    bottom: "conv5_2/incep/2_reduce"
    top: "conv5_2/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_2/incep/2_0/bn"
    type: "BatchNorm"
    bottom: "conv5_2/incep/2_0"
    top: "conv5_2/incep/2_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_2/incep/2_0/bn_scale"
    type: "Scale"
    bottom: "conv5_2/incep/2_0"
    top: "conv5_2/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_2/incep/2_0/relu"
    type: "ReLU"
    bottom: "conv5_2/incep/2_0"
    top: "conv5_2/incep/2_0"
}
layer {
    name: "conv5_2/incep/2_1/conv"
    type: "Convolution"
    bottom: "conv5_2/incep/2_0"
    top: "conv5_2/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_2/incep/2_1/bn"
    type: "BatchNorm"
    bottom: "conv5_2/incep/2_1"
    top: "conv5_2/incep/2_1"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_2/incep/2_1/bn_scale"
    type: "Scale"
    bottom: "conv5_2/incep/2_1"
    top: "conv5_2/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_2/incep/2_1/relu"
    type: "ReLU"
    bottom: "conv5_2/incep/2_1"
    top: "conv5_2/incep/2_1"
}
layer {
    name: "conv5_2/incep"
    type: "Concat"
    bottom: "conv5_2/incep/0"
    bottom: "conv5_2/incep/1_0"
    bottom: "conv5_2/incep/2_1"
    top: "conv5_2/incep"
}
layer {
    name: "conv5_2/out/conv"
    type: "Convolution"
    bottom: "conv5_2/incep"
    top: "conv5_2/out"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 384
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_2/input"
    type: "Power"
    bottom: "conv5_1"
    top: "conv5_2/input"
    power_param {
        power: 1
        scale: 1
        shift: 0
    }
}
layer {
    name: "conv5_2"
    type: "Eltwise"
    bottom: "conv5_2/out"
    bottom: "conv5_2/input"
    top: "conv5_2"
    eltwise_param {
        operation: SUM
        coeff: 1
        coeff: 1
    }
}
layer {
    name: "conv5_3/incep/bn"
    type: "BatchNorm"
    bottom: "conv5_2"
    top: "conv5_3/incep/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_3/incep/bn_scale"
    type: "Scale"
    bottom: "conv5_3/incep/pre"
    top: "conv5_3/incep/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_3/incep/relu"
    type: "ReLU"
    bottom: "conv5_3/incep/pre"
    top: "conv5_3/incep/pre"
}
layer {
    name: "conv5_3/incep/0/conv"
    type: "Convolution"
    bottom: "conv5_3/incep/pre"
    top: "conv5_3/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_3/incep/0/bn"
    type: "BatchNorm"
    bottom: "conv5_3/incep/0"
    top: "conv5_3/incep/0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_3/incep/0/bn_scale"
    type: "Scale"
    bottom: "conv5_3/incep/0"
    top: "conv5_3/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_3/incep/0/relu"
    type: "ReLU"
    bottom: "conv5_3/incep/0"
    top: "conv5_3/incep/0"
}
layer {
    name: "conv5_3/incep/1_reduce/conv"
    type: "Convolution"
    bottom: "conv5_3/incep/pre"
    top: "conv5_3/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 96
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_3/incep/1_reduce/bn"
    type: "BatchNorm"
    bottom: "conv5_3/incep/1_reduce"
    top: "conv5_3/incep/1_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_3/incep/1_reduce/bn_scale"
    type: "Scale"
    bottom: "conv5_3/incep/1_reduce"
    top: "conv5_3/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_3/incep/1_reduce/relu"
    type: "ReLU"
    bottom: "conv5_3/incep/1_reduce"
    top: "conv5_3/incep/1_reduce"
}
layer {
    name: "conv5_3/incep/1_0/conv"
    type: "Convolution"
    bottom: "conv5_3/incep/1_reduce"
    top: "conv5_3/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 192
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_3/incep/1_0/bn"
    type: "BatchNorm"
    bottom: "conv5_3/incep/1_0"
    top: "conv5_3/incep/1_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_3/incep/1_0/bn_scale"
    type: "Scale"
    bottom: "conv5_3/incep/1_0"
    top: "conv5_3/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_3/incep/1_0/relu"
    type: "ReLU"
    bottom: "conv5_3/incep/1_0"
    top: "conv5_3/incep/1_0"
}
layer {
    name: "conv5_3/incep/2_reduce/conv"
    type: "Convolution"
    bottom: "conv5_3/incep/pre"
    top: "conv5_3/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 32
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_3/incep/2_reduce/bn"
    type: "BatchNorm"
    bottom: "conv5_3/incep/2_reduce"
    top: "conv5_3/incep/2_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_3/incep/2_reduce/bn_scale"
    type: "Scale"
    bottom: "conv5_3/incep/2_reduce"
    top: "conv5_3/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_3/incep/2_reduce/relu"
    type: "ReLU"
    bottom: "conv5_3/incep/2_reduce"
    top: "conv5_3/incep/2_reduce"
}
layer {
    name: "conv5_3/incep/2_0/conv"
    type: "Convolution"
    bottom: "conv5_3/incep/2_reduce"
    top: "conv5_3/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_3/incep/2_0/bn"
    type: "BatchNorm"
    bottom: "conv5_3/incep/2_0"
    top: "conv5_3/incep/2_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_3/incep/2_0/bn_scale"
    type: "Scale"
    bottom: "conv5_3/incep/2_0"
    top: "conv5_3/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_3/incep/2_0/relu"
    type: "ReLU"
    bottom: "conv5_3/incep/2_0"
    top: "conv5_3/incep/2_0"
}
layer {
    name: "conv5_3/incep/2_1/conv"
    type: "Convolution"
    bottom: "conv5_3/incep/2_0"
    top: "conv5_3/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_3/incep/2_1/bn"
    type: "BatchNorm"
    bottom: "conv5_3/incep/2_1"
    top: "conv5_3/incep/2_1"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_3/incep/2_1/bn_scale"
    type: "Scale"
    bottom: "conv5_3/incep/2_1"
    top: "conv5_3/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_3/incep/2_1/relu"
    type: "ReLU"
    bottom: "conv5_3/incep/2_1"
    top: "conv5_3/incep/2_1"
}
layer {
    name: "conv5_3/incep"
    type: "Concat"
    bottom: "conv5_3/incep/0"
    bottom: "conv5_3/incep/1_0"
    bottom: "conv5_3/incep/2_1"
    top: "conv5_3/incep"
}
layer {
    name: "conv5_3/out/conv"
    type: "Convolution"
    bottom: "conv5_3/incep"
    top: "conv5_3/out"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }
    convolution_param {
        num_output: 384
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
            value: 0.1
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_3/input"
    type: "Power"
    bottom: "conv5_2"
    top: "conv5_3/input"
    power_param {
        power: 1
        scale: 1
        shift: 0
    }
}
layer {
    name: "conv5_3"
    type: "Eltwise"
    bottom: "conv5_3/out"
    bottom: "conv5_3/input"
    top: "conv5_3"
    eltwise_param {
        operation: SUM
        coeff: 1
        coeff: 1
    }
}
layer {
    name: "conv5_4/incep/bn"
    type: "BatchNorm"
    bottom: "conv5_3"
    top: "conv5_4/incep/pre"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_4/incep/bn_scale"
    type: "Scale"
    bottom: "conv5_4/incep/pre"
    top: "conv5_4/incep/pre"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_4/incep/relu"
    type: "ReLU"
    bottom: "conv5_4/incep/pre"
    top: "conv5_4/incep/pre"
}
layer {
    name: "conv5_4/incep/0/conv"
    type: "Convolution"
    bottom: "conv5_4/incep/pre"
    top: "conv5_4/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_4/incep/0/bn"
    type: "BatchNorm"
    bottom: "conv5_4/incep/0"
    top: "conv5_4/incep/0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_4/incep/0/bn_scale"
    type: "Scale"
    bottom: "conv5_4/incep/0"
    top: "conv5_4/incep/0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_4/incep/0/relu"
    type: "ReLU"
    bottom: "conv5_4/incep/0"
    top: "conv5_4/incep/0"
}
layer {
    name: "conv5_4/incep/1_reduce/conv"
    type: "Convolution"
    bottom: "conv5_4/incep/pre"
    top: "conv5_4/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 96
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_4/incep/1_reduce/bn"
    type: "BatchNorm"
    bottom: "conv5_4/incep/1_reduce"
    top: "conv5_4/incep/1_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_4/incep/1_reduce/bn_scale"
    type: "Scale"
    bottom: "conv5_4/incep/1_reduce"
    top: "conv5_4/incep/1_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_4/incep/1_reduce/relu"
    type: "ReLU"
    bottom: "conv5_4/incep/1_reduce"
    top: "conv5_4/incep/1_reduce"
}
layer {
    name: "conv5_4/incep/1_0/conv"
    type: "Convolution"
    bottom: "conv5_4/incep/1_reduce"
    top: "conv5_4/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 192
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_4/incep/1_0/bn"
    type: "BatchNorm"
    bottom: "conv5_4/incep/1_0"
    top: "conv5_4/incep/1_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_4/incep/1_0/bn_scale"
    type: "Scale"
    bottom: "conv5_4/incep/1_0"
    top: "conv5_4/incep/1_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_4/incep/1_0/relu"
    type: "ReLU"
    bottom: "conv5_4/incep/1_0"
    top: "conv5_4/incep/1_0"
}
layer {
    name: "conv5_4/incep/2_reduce/conv"
    type: "Convolution"
    bottom: "conv5_4/incep/pre"
    top: "conv5_4/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 32
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_4/incep/2_reduce/bn"
    type: "BatchNorm"
    bottom: "conv5_4/incep/2_reduce"
    top: "conv5_4/incep/2_reduce"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_4/incep/2_reduce/bn_scale"
    type: "Scale"
    bottom: "conv5_4/incep/2_reduce"
    top: "conv5_4/incep/2_reduce"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_4/incep/2_reduce/relu"
    type: "ReLU"
    bottom: "conv5_4/incep/2_reduce"
    top: "conv5_4/incep/2_reduce"
}
layer {
    name: "conv5_4/incep/2_0/conv"
    type: "Convolution"
    bottom: "conv5_4/incep/2_reduce"
    top: "conv5_4/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_4/incep/2_0/bn"
    type: "BatchNorm"
    bottom: "conv5_4/incep/2_0"
    top: "conv5_4/incep/2_0"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_4/incep/2_0/bn_scale"
    type: "Scale"
    bottom: "conv5_4/incep/2_0"
    top: "conv5_4/incep/2_0"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_4/incep/2_0/relu"
    type: "ReLU"
    bottom: "conv5_4/incep/2_0"
    top: "conv5_4/incep/2_0"
}
layer {
    name: "conv5_4/incep/2_1/conv"
    type: "Convolution"
    bottom: "conv5_4/incep/2_0"
    top: "conv5_4/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 64
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 1
        pad_w: 1
        kernel_h: 3
        kernel_w: 3
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_4/incep/2_1/bn"
    type: "BatchNorm"
    bottom: "conv5_4/incep/2_1"
    top: "conv5_4/incep/2_1"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_4/incep/2_1/bn_scale"
    type: "Scale"
    bottom: "conv5_4/incep/2_1"
    top: "conv5_4/incep/2_1"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_4/incep/2_1/relu"
    type: "ReLU"
    bottom: "conv5_4/incep/2_1"
    top: "conv5_4/incep/2_1"
}
layer {
    name: "conv5_4/incep"
    type: "Concat"
    bottom: "conv5_4/incep/0"
    bottom: "conv5_4/incep/1_0"
    bottom: "conv5_4/incep/2_1"
    top: "conv5_4/incep"
}
layer {
    name: "conv5_4/out/conv"
    type: "Convolution"
    bottom: "conv5_4/incep"
    top: "conv5_4/out"
    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    convolution_param {
        num_output: 384
        bias_term: false
        weight_filler {
            type: "xavier"
        }
        pad_h: 0
        pad_w: 0
        kernel_h: 1
        kernel_w: 1
        stride_h: 1
        stride_w: 1
    }
}
layer {
    name: "conv5_4/out/bn"
    type: "BatchNorm"
    bottom: "conv5_4/out"
    top: "conv5_4/out"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_4/out/bn_scale"
    type: "Scale"
    bottom: "conv5_4/out"
    top: "conv5_4/out"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_4/input"
    type: "Power"
    bottom: "conv5_3"
    top: "conv5_4/input"
    power_param {
        power: 1
        scale: 1
        shift: 0
    }
}
layer {
    name: "conv5_4"
    type: "Eltwise"
    bottom: "conv5_4/out"
    bottom: "conv5_4/input"
    top: "conv5_4"
    eltwise_param {
        operation: SUM
        coeff: 1
        coeff: 1
    }
}
layer {
    name: "conv5_4/last_bn"
    type: "BatchNorm"
    bottom: "conv5_4"
    top: "conv5_4"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    batch_norm_param {
        use_global_stats: true
    }
}
layer {
    name: "conv5_4/last_bn_scale"
    type: "Scale"
    bottom: "conv5_4"
    top: "conv5_4"
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    param {
        lr_mult: 1.0
        decay_mult: 0
    }
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5_4/last_relu"
    type: "ReLU"
    bottom: "conv5_4"
    top: "conv5_4"
}

##################################################################
# rpn proposal
##################################################################
layer {
    bottom: "conv5_4"
    top: "p5"
    name: "p5"
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        weight_filler { type: "gaussian" std: 0.001 }
        bias_filler { type: "constant" value: 0 }

    }
}

layer {
    name: "upP5"
    type: "Deconvolution"
    bottom: "p5" 
    top: "upP5"
    convolution_param {
        kernel_h : 4
        kernel_w : 4
        stride_h: 2
        stride_w: 2
        pad_h: 1
        pad_w: 1
        num_output: 256
        group: 256
        bias_term: false
        weight_filler {
            type: "bilinear"
        }
    }
    param { lr_mult: 0 decay_mult: 0 } 
}

layer {
    bottom: "conv4_4"
    top: "c4"
    name: "newC4"
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        weight_filler { type: "gaussian" std: 0.001 }
        bias_filler { type: "constant" value: 0.0 }

    }
}

layer {
    name: "p4"
    type: "Eltwise"
    bottom: "c4"
    bottom: "upP5"
    top: "p4"
    eltwise_param {
        operation: SUM
    }
}


layer {
    bottom: "p4"
    top: "p4_lateral"
    name: "p4_lateral"
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        weight_filler { type: "gaussian" std: 0.001 }
        bias_filler { type: "constant" value: 0.0 }

    }
}
layer {
    name: "upP4"
    type: "Deconvolution"
    bottom: "p4_lateral" 
    top: "upP4"
    convolution_param {
        kernel_h : 4
        kernel_w : 4
        stride_h: 2
        stride_w: 2
        pad_h: 1
        pad_w: 1
        num_output: 256
        group: 256
        bias_term: false
        weight_filler {
            type: "bilinear"
        }
    }
    param { lr_mult: 0 decay_mult: 0 } 
}


layer {
    bottom: "conv3_4"
    top: "c3"
    name: "newC3"
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        weight_filler { type: "gaussian" std: 0.001 }
        bias_filler { type: "constant" value: 0.0 }

    }
}
layer {
    name: "p3"
    type: "Eltwise"
    bottom: "c3"
    bottom: "upP4"
    top: "p3"
    eltwise_param {
        operation: SUM
    }
}


layer {
    bottom: "p3"
    top: "p3_lateral"
    name: "p3_lateral"
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        weight_filler { type: "gaussian" std: 0.001 }
        bias_filler { type: "constant" value: 0.0 }

    }
}

layer {
    bottom: "conv3_1/1/pre"
    top: "c2"
    name: "newC2"
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        weight_filler { type: "gaussian" std: 0.001 }
        bias_filler { type: "constant" value: 0.0 }

    }
}
layer {
    name: "upP2"
    type: "Deconvolution"
    bottom: "p3_lateral" 
    top: "upP2"
    convolution_param {
        kernel_h : 4
        kernel_w : 4
        stride_h: 2
        stride_w: 2
        pad_h: 1
        pad_w: 1
        num_output: 256
        group: 256
        bias_term: false
        weight_filler {
            type: "bilinear"
        }
    }
    param { lr_mult: 0 decay_mult: 0 } 
}
layer {
    name: "p2"
    type: "Eltwise"
    bottom: "c2"
    bottom: "upP2"
    top: "p2"
    eltwise_param {
        operation: SUM
    }
}




####

#========= RPN/p2 ============

layer {
    name: "rpn_conv/3x3/p2"
    type: "Convolution"
    bottom: "p2"
    top: "rpn/output/p2"
    param { lr_mult: 1.0
            name: "rpn_conv_3x3_w"
            }
    param { lr_mult: 2.0
            name: "rpn_conv_3x3_b"
            }
    convolution_param {
        num_output: 512
        kernel_size: 3 pad: 1 stride: 1
        weight_filler { type: "gaussian" std: 0.01 }
        bias_filler { type: "constant" value: 0 }
    }
}
layer {
    name: "rpn_relu/3x3/p2"
    type: "ReLU"
    bottom: "rpn/output/p2"
    top: "rpn/output/p2"
}

layer {
    name: "rpn_cls_score/p2"
    type: "Convolution"
    bottom: "rpn/output/p2"
    top: "rpn_cls_score/p2"
    param { lr_mult: 1.0
            name: "rpn_cls_score_w" }
    param { lr_mult: 2.0
            name: "rpn_cls_score_b"
            }
    convolution_param {
        num_output: 24   # 2(bg/fg) * 9(anchors)
        kernel_size: 1 pad: 0 stride: 1
        weight_filler { type: "gaussian" std: 0.01 }
        bias_filler { type: "constant" value: 0 }
    }
}

layer {
    name: "rpn_bbox_pred/p2"
    type: "Convolution"
    bottom: "rpn/output/p2"
    top: "rpn_bbox_pred/p2"
    param { lr_mult: 1.0
            name: "rpn_bbox_pred_w"
            }
    param { lr_mult: 2.0
            name: "rpn_bbox_pred_b"
            }
    convolution_param {
        num_output: 48   # 4 * 9(anchors)
        kernel_size: 1 pad: 0 stride: 1
        weight_filler { type: "gaussian" std: 0.01 }
        bias_filler { type: "constant" value: 0 }
    }
}

######

layer {
    bottom: "rpn_cls_score/p2"
    top: "rpn_cls_score_reshape/p2"
    name: "rpn_cls_score_reshape/p2"
    type: "Reshape"
    reshape_param { shape {dim: 0 dim: 2 dim: -1 dim:0} }
}

layer {
    name: 'rpn-data/p2'
    type: 'Python'
    bottom: 'rpn_cls_score/p2'
    bottom: 'gt_boxes'
    bottom: 'im_info'
    bottom: 'data'
    top: 'rpn_labels/p2'
    top: 'rpn_bbox_targets/p2'
    top: 'rpn_bbox_inside_weights/p2'
    top: 'rpn_bbox_outside_weights/p2'
    include { phase: TRAIN }
    python_param {
        module: 'rpn.anchor_target_layer'
        layer: 'AnchorTargetLayer'
        param_str: "{'feat_stride': 4, 'ratios': [0.5, 1.0, 2.0], 'scales': [2, 4, 8, 16]}"
    }
}
layer {
    name: "rpn_loss_cls/p2"
    type: "SoftmaxWithLoss"
    bottom: "rpn_cls_score_reshape/p2"
    bottom: "rpn_labels/p2"
    propagate_down: 1
    propagate_down: 0
    top: "rpn_loss_cls/p2"
    include { phase: TRAIN }
    loss_weight: 1
    loss_param { ignore_label: -1 normalize: true }
}
layer {
    name: "rpn_loss_bbox/p2"
    type: "SmoothL1Loss"
    bottom: "rpn_bbox_pred/p2"
    bottom: "rpn_bbox_targets/p2"
    bottom: "rpn_bbox_inside_weights/p2"
    bottom: "rpn_bbox_outside_weights/p2"
    top: "rpn_loss_bbox/p2"
    include { phase: TRAIN }
    loss_weight: 1
    smooth_l1_loss_param { sigma: 3.0 }
}

#========= RPN/p3 ============

layer {
    name: "rpn_conv/3x3/p3"
    type: "Convolution"
    bottom: "p3"
    top: "rpn/output/p3"
    param { lr_mult: 1.0
            name: "rpn_conv_3x3_w"
            }
    param { lr_mult: 2.0 
            name: "rpn_conv_3x3_b"
            }
    convolution_param {
        num_output: 512
        kernel_size: 3 pad: 1 stride: 1
        weight_filler { type: "gaussian" std: 0.001 }
        bias_filler { type: "constant" value: 0 }
    }
}
layer {
    name: "rpn_relu/3x3/p3"
    type: "ReLU"
    bottom: "rpn/output/p3"
    top: "rpn/output/p3"
}

layer {
    name: "rpn_cls_score/p3"
    type: "Convolution"
    bottom: "rpn/output/p3"
    top: "rpn_cls_score/p3"
    param { lr_mult: 1.0 
            name: "rpn_cls_score_w"
            }
    param { lr_mult: 2.0
            name: "rpn_cls_score_b"
            }
    convolution_param {
        num_output: 24   # 2(bg/fg) * 9(anchors)
        kernel_size: 1 pad: 0 stride: 1
        weight_filler { type: "gaussian" std: 0.001 }
        bias_filler { type: "constant" value: 0 }
    }
}

layer {
    name: "rpn_bbox_pred/p3"
    type: "Convolution"
    bottom: "rpn/output/p3"
    top: "rpn_bbox_pred/p3"
    param { lr_mult: 1.0
            name:"rpn_bbox_pred_w"
            }
    param { lr_mult: 2.0
            name:"rpn_bbox_pred_b" 
            }
    convolution_param {
        num_output: 48   # 4 * 9(anchors)
        kernel_size: 1 pad: 0 stride: 1
        weight_filler { type: "gaussian" std: 0.001 }
        bias_filler { type: "constant" value: 0 }
    }
}

######

layer {
    bottom: "rpn_cls_score/p3"
    top: "rpn_cls_score_reshape/p3"
    name: "rpn_cls_score_reshape/p3"
    type: "Reshape"
    reshape_param { shape {dim: 0 dim: 2 dim: -1 dim:0} }
}


layer {
    name: 'rpn-data/p3'
    type: 'Python'
    bottom: 'rpn_cls_score/p3'
    bottom: 'gt_boxes'
    bottom: 'im_info'
    bottom: 'data'
    top: 'rpn_labels/p3'
    top: 'rpn_bbox_targets/p3'
    top: 'rpn_bbox_inside_weights/p3'
    top: 'rpn_bbox_outside_weights/p3'
    include { phase: TRAIN }
    python_param {
        module: 'rpn.anchor_target_layer'
        layer: 'AnchorTargetLayer'
        param_str: "{'feat_stride': 8, 'ratios': [0.5, 1.0, 2.0], 'scales': [2, 4, 8, 16]}"
    }
}
layer {
    name: "rpn_loss_cls/p3"
    type: "SoftmaxWithLoss"
    bottom: "rpn_cls_score_reshape/p3"
    bottom: "rpn_labels/p3"
    propagate_down: 1
    propagate_down: 0
    top: "rpn_loss_cls/p3"
    include { phase: TRAIN }
    loss_weight: 1
    loss_param { ignore_label: -1 normalize: true }
}
layer {
    name: "rpn_loss_bbox/p3"
    type: "SmoothL1Loss"
    bottom: "rpn_bbox_pred/p3"
    bottom: "rpn_bbox_targets/p3"
    bottom: "rpn_bbox_inside_weights/p3"
    bottom: "rpn_bbox_outside_weights/p3"
    top: "rpn_loss_bbox/p3"
    include { phase: TRAIN }
    loss_weight: 1
    smooth_l1_loss_param { sigma: 3.0 }
}


#========= RPN/p4 ============

layer {
    name: "rpn_conv/3x3/p4"
    type: "Convolution"
    bottom: "p4"
    top: "rpn/output/p4"
    param { lr_mult: 1.0
            name: "rpn_conv_3x3_w"
            }
    param { lr_mult: 2.0 
            name: "rpn_conv_3x3_b"
            }
    convolution_param {
        num_output: 512
        kernel_size: 3 pad: 1 stride: 1
        weight_filler { type: "gaussian" std: 0.001 }
        bias_filler { type: "constant" value: 0 }
    }
}
layer {
    name: "rpn_relu/3x3/p4"
    type: "ReLU"
    bottom: "rpn/output/p4"
    top: "rpn/output/p4"
}

layer {
    name: "rpn_cls_score/p4"
    type: "Convolution"
    bottom: "rpn/output/p4"
    top: "rpn_cls_score/p4"
    param { lr_mult: 1.0 
            name:"rpn_cls_score_w"
            }
    param { lr_mult: 2.0
            name:"rpn_cls_score_b"
            }
    convolution_param {
        num_output: 24   # 2(bg/fg) * 9(anchors)
        kernel_size: 1 pad: 0 stride: 1
        weight_filler { type: "gaussian" std: 0.001 }
        bias_filler { type: "constant" value: 0 }
    }
}

layer {
    name: "rpn_bbox_pred/p4"
    type: "Convolution"
    bottom: "rpn/output/p4"
    top: "rpn_bbox_pred/p4"
    param { lr_mult: 1.0
            name:"rpn_bbox_pred_w"
            }
    param { lr_mult: 2.0
            name:"rpn_bbox_pred_b"
            }
    convolution_param {
        num_output: 48   # 4 * 9(anchors)
        kernel_size: 1 pad: 0 stride: 1
        weight_filler { type: "gaussian" std: 0.001 }
        bias_filler { type: "constant" value: 0 }
    }
}

######

layer {
    bottom: "rpn_cls_score/p4"
    top: "rpn_cls_score_reshape/p4"
    name: "rpn_cls_score_reshape/p4"
    type: "Reshape"
    reshape_param { shape {dim: 0 dim: 2 dim: -1 dim:0} }
}

layer {
    name: 'rpn-data/p4'
    type: 'Python'
    bottom: 'rpn_cls_score/p4'
    bottom: 'gt_boxes'
    bottom: 'im_info'
    bottom: 'data'
    top: 'rpn_labels/p4'
    top: 'rpn_bbox_targets/p4'
    top: 'rpn_bbox_inside_weights/p4'
    top: 'rpn_bbox_outside_weights/p4'
    include { phase: TRAIN }
    python_param {
        module: 'rpn.anchor_target_layer'
        layer: 'AnchorTargetLayer'
        param_str: "{'feat_stride': 16, 'ratios': [0.5, 1.0, 2.0], 'scales': [2, 4, 8, 16]}"
    }
}
layer {
    name: "rpn_loss_cls/p4"
    type: "SoftmaxWithLoss"
    bottom: "rpn_cls_score_reshape/p4"
    bottom: "rpn_labels/p4"
    propagate_down: 1
    propagate_down: 0
    top: "rpn_loss_cls/p4"
    include { phase: TRAIN }
    loss_weight: 1
    loss_param { ignore_label: -1 normalize: true }
}
layer {
    name: "rpn_loss_bbox/p4"
    type: "SmoothL1Loss"
    bottom: "rpn_bbox_pred/p4"
    bottom: "rpn_bbox_targets/p4"
    bottom: "rpn_bbox_inside_weights/p4"
    bottom: "rpn_bbox_outside_weights/p4"
    top: "rpn_loss_bbox/p4"
    include { phase: TRAIN }
    loss_weight: 1
    smooth_l1_loss_param { sigma: 3.0 }
}

#========= RPN/p5 ============

layer {
    name: "rpn_conv/3x3/p5"
    type: "Convolution"
    bottom: "p5"
    top: "rpn/output/p5"
    param { lr_mult: 1.0
            name:"rpn_conv_3x3_w"
            }
    param { lr_mult: 2.0
            name:"rpn_conv_3x3_b"
            }
    convolution_param {
        num_output: 512
        kernel_size: 3 pad: 1 stride: 1
        weight_filler { type: "gaussian" std: 0.01 }
        bias_filler { type: "constant" value: 0 }
    }
}
layer {
    name: "rpn_relu/3x3/p5"
    type: "ReLU"
    bottom: "rpn/output/p5"
    top: "rpn/output/p5"
}

layer {
    name: "rpn_cls_score/p5"
    type: "Convolution"
    bottom: "rpn/output/p5"
    top: "rpn_cls_score/p5"
    param { lr_mult: 1.0
            name:"rpn_cls_score_w"

            }
    param { lr_mult: 2.0
            name:"rpn_cls_score_b"
            }
    convolution_param {
        num_output: 24   # 2(bg/fg) * 9(anchors)
        kernel_size: 1 pad: 0 stride: 1
        weight_filler { type: "gaussian" std: 0.01 }
        bias_filler { type: "constant" value: 0 }
    }
}

layer {
    name: "rpn_bbox_pred/p5"
    type: "Convolution"
    bottom: "rpn/output/p5"
    top: "rpn_bbox_pred/p5"
    param { lr_mult: 1.0 
            name:"rpn_bbox_pred_w"
            }
    param { lr_mult: 2.0
            name:"rpn_bbox_pred_b"
            }
    convolution_param {
        num_output: 48  # 4 * 9(anchors)
        kernel_size: 1 pad: 0 stride: 1
        weight_filler { type: "gaussian" std: 0.01 }
        bias_filler { type: "constant" value: 0 }
    }
}

######

layer {
    bottom: "rpn_cls_score/p5"
    top: "rpn_cls_score_reshape/p5"
    name: "rpn_cls_score_reshape/p5"
    type: "Reshape"
    reshape_param { shape {dim: 0 dim: 2 dim: -1 dim:0} }
}


layer {
    name: 'rpn-data/p5'
    type: 'Python'
    bottom: 'rpn_cls_score/p5'
    bottom: 'gt_boxes'
    bottom: 'im_info'
    bottom: 'data'
    top: 'rpn_labels/p5'
    top: 'rpn_bbox_targets/p5'
    top: 'rpn_bbox_inside_weights/p5'
    top: 'rpn_bbox_outside_weights/p5'
    include { phase: TRAIN }
    python_param {
        module: 'rpn.anchor_target_layer'
        layer: 'AnchorTargetLayer'
        param_str: "{'feat_stride': 32, 'ratios': [0.5, 1.0, 2.0], 'scales': [2, 4, 8, 16]}"
    }
}
layer {
    name: "rpn_loss_cls/p5"
    type: "SoftmaxWithLoss"
    bottom: "rpn_cls_score_reshape/p5"
    bottom: "rpn_labels/p5"
    propagate_down: 1
    propagate_down: 0
    top: "rpn_loss_cls/p5"
    include { phase: TRAIN }
    loss_weight: 1
    loss_param { ignore_label: -1 normalize: true }
}
layer {
    name: "rpn_loss_bbox/p5"
    type: "SmoothL1Loss"
    bottom: "rpn_bbox_pred/p5"
    bottom: "rpn_bbox_targets/p5"
    bottom: "rpn_bbox_inside_weights/p5"
    bottom: "rpn_bbox_outside_weights/p5"
    top: "rpn_loss_bbox/p5"
    include { phase: TRAIN }
    loss_weight: 1
    smooth_l1_loss_param { sigma: 3.0 }
}


###################################################
# Proposal
###################################################
layer {
    name: "rpn_cls_prob/p2"
    type: "Softmax"
    bottom: "rpn_cls_score_reshape/p2"
    top: "rpn_cls_prob/p2"
}
layer {
    name: 'rpn_cls_prob_reshape/p2'
    type: 'Reshape'
    bottom: 'rpn_cls_prob/p2'
    top: 'rpn_cls_prob_reshape/p2'
    reshape_param { shape { dim: 0 dim: 24 dim: -1 dim: 0 } }
}
layer {
    name: "rpn_cls_prob/p3"
    type: "Softmax"
    bottom: "rpn_cls_score_reshape/p3"
    top: "rpn_cls_prob/p3"
}
layer {
    name: 'rpn_cls_prob_reshape/p3'
    type: 'Reshape'
    bottom: 'rpn_cls_prob/p3'
    top: 'rpn_cls_prob_reshape/p3'
    reshape_param { shape { dim: 0 dim: 24 dim: -1 dim: 0 } }
}
layer {
    name: "rpn_cls_prob/p4"
    type: "Softmax"
    bottom: "rpn_cls_score_reshape/p4"
    top: "rpn_cls_prob/p4"
}
layer {
    name: 'rpn_cls_prob_reshape/p4'
    type: 'Reshape'
    bottom: 'rpn_cls_prob/p4'
    top: 'rpn_cls_prob_reshape/p4'
    reshape_param { shape { dim: 0 dim: 24 dim: -1 dim: 0 } }
}
layer {
    name: "rpn_cls_prob/p5"
    type: "Softmax"
    bottom: "rpn_cls_score_reshape/p5"
    top: "rpn_cls_prob/p5"
}
layer {
    name: 'rpn_cls_prob_reshape/p5'
    type: 'Reshape'
    bottom: 'rpn_cls_prob/p5'
    top: 'rpn_cls_prob_reshape/p5'
    reshape_param { shape { dim: 0 dim: 24 dim: -1 dim: 0 } }
}
layer {
    name: 'proposal/p2'
    type: 'Python'
    bottom: 'rpn_cls_prob_reshape/p2'
    bottom: 'rpn_bbox_pred/p2'
    bottom: 'im_info'
    top: 'rpn_rois/p2'
    #top: 'rpn_scores/p2'
    include { phase: TRAIN }
    python_param {
        module: 'rpn.proposal_layer'
        layer: 'ProposalLayer'
        param_str: "{'feat_stride': 4, 'ratios': [0.5, 1.0, 2.0], 'scales': [2, 4, 8, 16]}"
    }
}

layer {
    name: 'roi-data/p2'
    type: 'Python'
    bottom: 'rpn_rois/p2'
    bottom: 'gt_boxes'
    top: 'rois/p2'
    top: 'labels/p2'
    top: 'bbox_targets/p2'
    top: 'bbox_inside_weights/p2'
    top: 'bbox_outside_weights/p2'
    include { phase: TRAIN }	
    python_param {
        module: 'rpn.proposal_target_layer'
        layer: 'ProposalTargetLayer'
        param_str: "'num_classes': 2"
    }
}
layer {
    name: 'proposal/p3'
    type: 'Python'
    bottom: 'rpn_cls_prob_reshape/p3'
    bottom: 'rpn_bbox_pred/p3'
    bottom: 'im_info'
    top: 'rpn_rois/p3'
    #top: 'rpn_scores/p3'
    include { phase: TRAIN }
    python_param {
        module: 'rpn.proposal_layer'
        layer: 'ProposalLayer'
        param_str: "{'feat_stride': 8, 'ratios': [0.5, 1.0, 2.0], 'scales': [2, 4, 8, 16]}"
    }
}

layer {
    name: 'roi-data/p3'
    type: 'Python'
    bottom: 'rpn_rois/p3'
    bottom: 'gt_boxes'
    top: 'rois/p3'
    top: 'labels/p3'
    top: 'bbox_targets/p3'
    top: 'bbox_inside_weights/p3'
    top: 'bbox_outside_weights/p3'
    include { phase: TRAIN }	
    python_param {
        module: 'rpn.proposal_target_layer'
        layer: 'ProposalTargetLayer'
        param_str: "'num_classes': 2"
    }
}
layer {
    name: 'proposal/p4'
    type: 'Python'
    bottom: 'rpn_cls_prob_reshape/p4'
    bottom: 'rpn_bbox_pred/p4'
    bottom: 'im_info'
    top: 'rpn_rois/p4'
    #top: 'rpn_scores/p4'
    include { phase: TRAIN }
    python_param {
        module: 'rpn.proposal_layer'
        layer: 'ProposalLayer'
        param_str: "{'feat_stride': 16, 'ratios': [0.5, 1.0, 2.0], 'scales': [2, 4, 8, 16]}"
    }
}

layer {
    name: 'roi-data/p4'
    type: 'Python'
    bottom: 'rpn_rois/p4'
    bottom: 'gt_boxes'
    top: 'rois/p4'
    top: 'labels/p4'
    top: 'bbox_targets/p4'
    top: 'bbox_inside_weights/p4'
    top: 'bbox_outside_weights/p4'
    include { phase: TRAIN }	
    python_param {
        module: 'rpn.proposal_target_layer'
        layer: 'ProposalTargetLayer'
        param_str: "'num_classes': 2"
    }
}
layer {
    name: 'proposal/p5'
    type: 'Python'
    bottom: 'rpn_cls_prob_reshape/p5'
    bottom: 'rpn_bbox_pred/p5'
    bottom: 'im_info'
    top: 'rpn_rois/p5'
    #top: 'rpn_scores/p5'
    include { phase: TRAIN }
    python_param {
        module: 'rpn.proposal_layer'
        layer: 'ProposalLayer'
        param_str: "{'feat_stride': 32, 'ratios': [0.5, 1.0, 2.0], 'scales': [2, 4, 8, 16]}"
    }
}

layer {
    name: 'roi-data/p5'
    type: 'Python'
    bottom: 'rpn_rois/p5'
    bottom: 'gt_boxes'
    top: 'rois/p5'
    top: 'labels/p5'
    top: 'bbox_targets/p5'
    top: 'bbox_inside_weights/p5'
    top: 'bbox_outside_weights/p5'
    include { phase: TRAIN }	
    python_param {
        module: 'rpn.proposal_target_layer'
        layer: 'ProposalTargetLayer'
        param_str: "'num_classes': 2"
    }
}

layer {
    name: "bbox_targets"
    type: "Concat"
    bottom: "bbox_targets/p2"
    bottom: "bbox_targets/p3"
    bottom: "bbox_targets/p4"
    bottom: "bbox_targets/p5"
    top: "bbox_targets"
    concat_param {
        axis: 0
    }
}
layer {
    name: "bbox_inside_weights"
    type: "Concat"
    bottom: "bbox_inside_weights/p2"
    bottom: "bbox_inside_weights/p3"
    bottom: "bbox_inside_weights/p4"
    bottom: "bbox_inside_weights/p5"
    top: "bbox_inside_weights"
    concat_param {
        axis: 0
    }
}
layer {
    name: "bbox_outside_weights"
    type: "Concat"
    bottom: "bbox_outside_weights/p2"
    bottom: "bbox_outside_weights/p3"
    bottom: "bbox_outside_weights/p4"
    bottom: "bbox_outside_weights/p5"
    top: "bbox_outside_weights"
    concat_param {
        axis: 0
    }
}
layer {
    name: "labels"
    type: "Concat"
    bottom: "labels/p2"
    bottom: "labels/p3"
    bottom: "labels/p4"
    bottom: "labels/p5"
    top: "labels"
    concat_param {
        axis: 0
    }
}

##############################################
# RoiPooling
##############################################
layer {
    name: "roi_pool/p2"
    type: "ROIPooling"
    bottom: "p2"
    bottom: "rois/p2"
    top: "roi_pool/p2"
    roi_pooling_param {
        pooled_w: 7
        pooled_h: 7
        spatial_scale: 0.25 # 1/4
    }
}


layer {
    name: "roi_pool/p3"
    type: "ROIPooling"
    bottom: "p3"
    bottom: "rois/p3"
    top: "roi_pool/p3"
    roi_pooling_param {
        pooled_w: 7
        pooled_h: 7
        spatial_scale: 0.125 # 1/8
    }
}
layer {
    name: "roi_pool/p4"
    type: "ROIPooling"
    bottom: "p4"
    bottom: "rois/p4"
    top: "roi_pool/p4"
    roi_pooling_param {
        pooled_w: 7
        pooled_h: 7
        spatial_scale: 0.0625 # 1/16
    }
}

layer {
    name: "roi_pool/p5"
    type: "ROIPooling"
    bottom: "p5"
    bottom: "rois/p5"
    top: "roi_pool/p5"
    roi_pooling_param {
        pooled_w: 7
        pooled_h: 7
        spatial_scale: 0.03125 # 1/32
    }
}


layer {
    name: "roi_pooling"
    type: "Concat"
    bottom: "roi_pool/p2"
    bottom: "roi_pool/p3"
    bottom: "roi_pool/p4"
    bottom: "roi_pool/p5"
    top: "roi_pooling"
    concat_param {
        axis: 0
    }
}

##############################################
# boundingboxes regression
##############################################

layer {
    name: "fc6_"
    type: "InnerProduct"
    bottom: "roi_pooling"
    top: "fc6_"
    param {
        lr_mult: 1
        name: "rcnn_fc6__w"
    }
    param {
        lr_mult: 2
        name: "rcnn_fc6__b"
    }
    inner_product_param {
        num_output: 1024
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
        }
    }
}
layer {
    name: "relu6"
    type: "ReLU"
    bottom: "fc6_"
    top: "fc6_"
}

layer {
    name: "fc7_"
    type: "InnerProduct"
    bottom: "fc6_"
    top: "fc7_"
    param {
        lr_mult: 1
        name:"fc7__w"
    }
    param {
        lr_mult: 2
        name: "fc7__b"
    }
    inner_product_param {
        num_output: 1024
        weight_filler { 
            type: "xavier"  
        }  
        bias_filler {  
            type: "constant"  
        } 
    }
}
layer {
    name: "relu7"
    type: "ReLU"
    bottom: "fc7_"
    top: "fc7_"
}

layer {
    name: "cls_score"
    type: "InnerProduct"
    bottom: "fc7_"
    top: "cls_score"
    param {
        lr_mult: 1
        name:"cls_score_w"
    }
    param {
        lr_mult: 2
        name:"cls_score_b"
    }
    inner_product_param {
        num_output: 2
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}
layer {
    name: "bbox_pred"
    type: "InnerProduct"
    bottom: "fc7_"
    top: "bbox_pred"
    param {
        lr_mult: 1
        name:"bbox_pred_w"
    }
    param {
        lr_mult: 2
        name:"bbox_pred_b"
    }
    inner_product_param {
        num_output: 8
        weight_filler {
            type: "gaussian"
            std: 0.001
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}





layer {
    name: "loss_cls"
    type: "SoftmaxWithLoss"
    bottom: "cls_score"
    bottom: "labels"
    propagate_down: 1
    propagate_down: 0
    top: "loss_cls"
    loss_weight: 1
    loss_param{
        ignore_label: -1
        normalization: VALID
}
}
layer {
    name: "loss_bbox"
    type: "SmoothL1Loss"
    bottom: "bbox_pred"
    bottom: "bbox_targets"
    bottom: "bbox_inside_weights"
    bottom: "bbox_outside_weights"
    top: "loss_bbox"
    loss_weight: 1
}
