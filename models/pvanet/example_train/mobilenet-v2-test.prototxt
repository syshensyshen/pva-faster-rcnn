name: "PVANET-MOBILENET"

################################################################################
## Input
################################################################################

input: "data"
input_shape {
  dim: 1
  dim: 3
  dim: 640
  dim: 1056
}
input: "im_info"
input_shape {
  dim: 1
  dim: 6
}
################################################################################
## Convolution
################################################################################

layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1/bn"
  top: "conv1/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1/bn"
  top: "conv1/bn"
}
layer {
  name: "conv2_1/expand"
  type: "Convolution"
  bottom: "conv1/bn"
  top: "conv2_1/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/expand/bn"
  type: "BatchNorm"
  bottom: "conv2_1/expand"
  top: "conv2_1/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv2_1/expand/scale"
  type: "Scale"
  bottom: "conv2_1/expand/bn"
  top: "conv2_1/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1/expand"
  type: "ReLU"
  bottom: "conv2_1/expand/bn"
  top: "conv2_1/expand/bn"
}
layer {
  name: "conv2_1/dwise"
  type: "Convolution"
  bottom: "conv2_1/expand/bn"
  top: "conv2_1/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_1/dwise/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dwise"
  top: "conv2_1/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv2_1/dwise/scale"
  type: "Scale"
  bottom: "conv2_1/dwise/bn"
  top: "conv2_1/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1/dwise"
  type: "ReLU"
  bottom: "conv2_1/dwise/bn"
  top: "conv2_1/dwise/bn"
}
layer {
  name: "conv2_1/linear"
  type: "Convolution"
  bottom: "conv2_1/dwise/bn"
  top: "conv2_1/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/linear/bn"
  type: "BatchNorm"
  bottom: "conv2_1/linear"
  top: "conv2_1/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv2_1/linear/scale"
  type: "Scale"
  bottom: "conv2_1/linear/bn"
  top: "conv2_1/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2/expand"
  type: "Convolution"
  bottom: "conv2_1/linear/bn"
  top: "conv2_2/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/expand/bn"
  type: "BatchNorm"
  bottom: "conv2_2/expand"
  top: "conv2_2/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv2_2/expand/scale"
  type: "Scale"
  bottom: "conv2_2/expand/bn"
  top: "conv2_2/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2/expand"
  type: "ReLU"
  bottom: "conv2_2/expand/bn"
  top: "conv2_2/expand/bn"
}
layer {
  name: "conv2_2/dwise"
  type: "Convolution"
  bottom: "conv2_2/expand/bn"
  top: "conv2_2/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 96
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_2/dwise/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dwise"
  top: "conv2_2/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv2_2/dwise/scale"
  type: "Scale"
  bottom: "conv2_2/dwise/bn"
  top: "conv2_2/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2/dwise"
  type: "ReLU"
  bottom: "conv2_2/dwise/bn"
  top: "conv2_2/dwise/bn"
}
layer {
  name: "conv2_2/linear"
  type: "Convolution"
  bottom: "conv2_2/dwise/bn"
  top: "conv2_2/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 24
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/linear/bn"
  type: "BatchNorm"
  bottom: "conv2_2/linear"
  top: "conv2_2/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv2_2/linear/scale"
  type: "Scale"
  bottom: "conv2_2/linear/bn"
  top: "conv2_2/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1/expand"
  type: "Convolution"
  bottom: "conv2_2/linear/bn"
  top: "conv3_1/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 144
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/expand/bn"
  type: "BatchNorm"
  bottom: "conv3_1/expand"
  top: "conv3_1/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv3_1/expand/scale"
  type: "Scale"
  bottom: "conv3_1/expand/bn"
  top: "conv3_1/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1/expand"
  type: "ReLU"
  bottom: "conv3_1/expand/bn"
  top: "conv3_1/expand/bn"
}
layer {
  name: "conv3_1/dwise"
  type: "Convolution"
  bottom: "conv3_1/expand/bn"
  top: "conv3_1/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 144
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_1/dwise/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dwise"
  top: "conv3_1/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv3_1/dwise/scale"
  type: "Scale"
  bottom: "conv3_1/dwise/bn"
  top: "conv3_1/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1/dwise"
  type: "ReLU"
  bottom: "conv3_1/dwise/bn"
  top: "conv3_1/dwise/bn"
}
layer {
  name: "conv3_1/linear"
  type: "Convolution"
  bottom: "conv3_1/dwise/bn"
  top: "conv3_1/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 24
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/linear/bn"
  type: "BatchNorm"
  bottom: "conv3_1/linear"
  top: "conv3_1/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv3_1/linear/scale"
  type: "Scale"
  bottom: "conv3_1/linear/bn"
  top: "conv3_1/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "block_3_1"
  type: "Eltwise"
  bottom: "conv2_2/linear/bn"
  bottom: "conv3_1/linear/bn"
  top: "block_3_1"
}
layer {
  name: "conv3_2/expand"
  type: "Convolution"
  bottom: "block_3_1"
  top: "conv3_2/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 144
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/expand/bn"
  type: "BatchNorm"
  bottom: "conv3_2/expand"
  top: "conv3_2/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv3_2/expand/scale"
  type: "Scale"
  bottom: "conv3_2/expand/bn"
  top: "conv3_2/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2/expand"
  type: "ReLU"
  bottom: "conv3_2/expand/bn"
  top: "conv3_2/expand/bn"
}
layer {
  name: "conv3_2/dwise"
  type: "Convolution"
  bottom: "conv3_2/expand/bn"
  top: "conv3_2/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 144
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_2/dwise/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dwise"
  top: "conv3_2/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv3_2/dwise/scale"
  type: "Scale"
  bottom: "conv3_2/dwise/bn"
  top: "conv3_2/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2/dwise"
  type: "ReLU"
  bottom: "conv3_2/dwise/bn"
  top: "conv3_2/dwise/bn"
}
layer {
  name: "conv3_2/linear"
  type: "Convolution"
  bottom: "conv3_2/dwise/bn"
  top: "conv3_2/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/linear/bn"
  type: "BatchNorm"
  bottom: "conv3_2/linear"
  top: "conv3_2/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv3_2/linear/scale"
  type: "Scale"
  bottom: "conv3_2/linear/bn"
  top: "conv3_2/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/expand"
  type: "Convolution"
  bottom: "conv3_2/linear/bn"
  top: "conv4_1/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/expand/bn"
  type: "BatchNorm"
  bottom: "conv4_1/expand"
  top: "conv4_1/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_1/expand/scale"
  type: "Scale"
  bottom: "conv4_1/expand/bn"
  top: "conv4_1/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1/expand"
  type: "ReLU"
  bottom: "conv4_1/expand/bn"
  top: "conv4_1/expand/bn"
}
layer {
  name: "conv4_1/dwise"
  type: "Convolution"
  bottom: "conv4_1/expand/bn"
  top: "conv4_1/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 192
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4_1/dwise/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dwise"
  top: "conv4_1/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_1/dwise/scale"
  type: "Scale"
  bottom: "conv4_1/dwise/bn"
  top: "conv4_1/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1/dwise"
  type: "ReLU"
  bottom: "conv4_1/dwise/bn"
  top: "conv4_1/dwise/bn"
}
layer {
  name: "conv4_1/linear"
  type: "Convolution"
  bottom: "conv4_1/dwise/bn"
  top: "conv4_1/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/linear/bn"
  type: "BatchNorm"
  bottom: "conv4_1/linear"
  top: "conv4_1/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_1/linear/scale"
  type: "Scale"
  bottom: "conv4_1/linear/bn"
  top: "conv4_1/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "block_4_1"
  type: "Eltwise"
  bottom: "conv3_2/linear/bn"
  bottom: "conv4_1/linear/bn"
  top: "block_4_1"
}
layer {
  name: "conv4_2/expand"
  type: "Convolution"
  bottom: "block_4_1"
  top: "conv4_2/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/expand/bn"
  type: "BatchNorm"
  bottom: "conv4_2/expand"
  top: "conv4_2/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_2/expand/scale"
  type: "Scale"
  bottom: "conv4_2/expand/bn"
  top: "conv4_2/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2/expand"
  type: "ReLU"
  bottom: "conv4_2/expand/bn"
  top: "conv4_2/expand/bn"
}
layer {
  name: "conv4_2/dwise"
  type: "Convolution"
  bottom: "conv4_2/expand/bn"
  top: "conv4_2/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 192
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4_2/dwise/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dwise"
  top: "conv4_2/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_2/dwise/scale"
  type: "Scale"
  bottom: "conv4_2/dwise/bn"
  top: "conv4_2/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2/dwise"
  type: "ReLU"
  bottom: "conv4_2/dwise/bn"
  top: "conv4_2/dwise/bn"
}
layer {
  name: "conv4_2/linear"
  type: "Convolution"
  bottom: "conv4_2/dwise/bn"
  top: "conv4_2/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/linear/bn"
  type: "BatchNorm"
  bottom: "conv4_2/linear"
  top: "conv4_2/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_2/linear/scale"
  type: "Scale"
  bottom: "conv4_2/linear/bn"
  top: "conv4_2/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "block_4_2"
  type: "Eltwise"
  bottom: "block_4_1"
  bottom: "conv4_2/linear/bn"
  top: "block_4_2"
}
layer {
  name: "conv4_3/expand"
  type: "Convolution"
  bottom: "block_4_2"
  top: "conv4_3/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_3/expand/bn"
  type: "BatchNorm"
  bottom: "conv4_3/expand"
  top: "conv4_3/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_3/expand/scale"
  type: "Scale"
  bottom: "conv4_3/expand/bn"
  top: "conv4_3/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3/expand"
  type: "ReLU"
  bottom: "conv4_3/expand/bn"
  top: "conv4_3/expand/bn"
}
layer {
  name: "conv4_3/dwise"
  type: "Convolution"
  bottom: "conv4_3/expand/bn"
  top: "conv4_3/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 192
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4_3/dwise/bn"
  type: "BatchNorm"
  bottom: "conv4_3/dwise"
  top: "conv4_3/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_3/dwise/scale"
  type: "Scale"
  bottom: "conv4_3/dwise/bn"
  top: "conv4_3/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3/dwise"
  type: "ReLU"
  bottom: "conv4_3/dwise/bn"
  top: "conv4_3/dwise/bn"
}
layer {
  name: "conv4_3/linear"
  type: "Convolution"
  bottom: "conv4_3/dwise/bn"
  top: "conv4_3/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_3/linear/bn"
  type: "BatchNorm"
  bottom: "conv4_3/linear"
  top: "conv4_3/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_3/linear/scale"
  type: "Scale"
  bottom: "conv4_3/linear/bn"
  top: "conv4_3/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4/expand"
  type: "Convolution"
  bottom: "conv4_3/linear/bn"
  top: "conv4_4/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_4/expand/bn"
  type: "BatchNorm"
  bottom: "conv4_4/expand"
  top: "conv4_4/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_4/expand/scale"
  type: "Scale"
  bottom: "conv4_4/expand/bn"
  top: "conv4_4/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_4/expand"
  type: "ReLU"
  bottom: "conv4_4/expand/bn"
  top: "conv4_4/expand/bn"
}
layer {
  name: "conv4_4/dwise"
  type: "Convolution"
  bottom: "conv4_4/expand/bn"
  top: "conv4_4/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 384
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4_4/dwise/bn"
  type: "BatchNorm"
  bottom: "conv4_4/dwise"
  top: "conv4_4/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_4/dwise/scale"
  type: "Scale"
  bottom: "conv4_4/dwise/bn"
  top: "conv4_4/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_4/dwise"
  type: "ReLU"
  bottom: "conv4_4/dwise/bn"
  top: "conv4_4/dwise/bn"
}
layer {
  name: "conv4_4/linear"
  type: "Convolution"
  bottom: "conv4_4/dwise/bn"
  top: "conv4_4/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_4/linear/bn"
  type: "BatchNorm"
  bottom: "conv4_4/linear"
  top: "conv4_4/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_4/linear/scale"
  type: "Scale"
  bottom: "conv4_4/linear/bn"
  top: "conv4_4/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "block_4_4"
  type: "Eltwise"
  bottom: "conv4_3/linear/bn"
  bottom: "conv4_4/linear/bn"
  top: "block_4_4"
}
layer {
  name: "conv4_5/expand"
  type: "Convolution"
  bottom: "block_4_4"
  top: "conv4_5/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_5/expand/bn"
  type: "BatchNorm"
  bottom: "conv4_5/expand"
  top: "conv4_5/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_5/expand/scale"
  type: "Scale"
  bottom: "conv4_5/expand/bn"
  top: "conv4_5/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_5/expand"
  type: "ReLU"
  bottom: "conv4_5/expand/bn"
  top: "conv4_5/expand/bn"
}
layer {
  name: "conv4_5/dwise"
  type: "Convolution"
  bottom: "conv4_5/expand/bn"
  top: "conv4_5/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 384
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4_5/dwise/bn"
  type: "BatchNorm"
  bottom: "conv4_5/dwise"
  top: "conv4_5/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_5/dwise/scale"
  type: "Scale"
  bottom: "conv4_5/dwise/bn"
  top: "conv4_5/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_5/dwise"
  type: "ReLU"
  bottom: "conv4_5/dwise/bn"
  top: "conv4_5/dwise/bn"
}
layer {
  name: "conv4_5/linear"
  type: "Convolution"
  bottom: "conv4_5/dwise/bn"
  top: "conv4_5/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_5/linear/bn"
  type: "BatchNorm"
  bottom: "conv4_5/linear"
  top: "conv4_5/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_5/linear/scale"
  type: "Scale"
  bottom: "conv4_5/linear/bn"
  top: "conv4_5/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "block_4_5"
  type: "Eltwise"
  bottom: "block_4_4"
  bottom: "conv4_5/linear/bn"
  top: "block_4_5"
}
layer {
  name: "conv4_6/expand"
  type: "Convolution"
  bottom: "block_4_5"
  top: "conv4_6/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_6/expand/bn"
  type: "BatchNorm"
  bottom: "conv4_6/expand"
  top: "conv4_6/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_6/expand/scale"
  type: "Scale"
  bottom: "conv4_6/expand/bn"
  top: "conv4_6/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_6/expand"
  type: "ReLU"
  bottom: "conv4_6/expand/bn"
  top: "conv4_6/expand/bn"
}
layer {
  name: "conv4_6/dwise"
  type: "Convolution"
  bottom: "conv4_6/expand/bn"
  top: "conv4_6/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 384
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4_6/dwise/bn"
  type: "BatchNorm"
  bottom: "conv4_6/dwise"
  top: "conv4_6/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_6/dwise/scale"
  type: "Scale"
  bottom: "conv4_6/dwise/bn"
  top: "conv4_6/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_6/dwise"
  type: "ReLU"
  bottom: "conv4_6/dwise/bn"
  top: "conv4_6/dwise/bn"
}
layer {
  name: "conv4_6/linear"
  type: "Convolution"
  bottom: "conv4_6/dwise/bn"
  top: "conv4_6/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_6/linear/bn"
  type: "BatchNorm"
  bottom: "conv4_6/linear"
  top: "conv4_6/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_6/linear/scale"
  type: "Scale"
  bottom: "conv4_6/linear/bn"
  top: "conv4_6/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "block_4_6"
  type: "Eltwise"
  bottom: "block_4_5"
  bottom: "conv4_6/linear/bn"
  top: "block_4_6"
}
layer {
  name: "conv4_7/expand"
  type: "Convolution"
  bottom: "block_4_6"
  top: "conv4_7/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_7/expand/bn"
  type: "BatchNorm"
  bottom: "conv4_7/expand"
  top: "conv4_7/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_7/expand/scale"
  type: "Scale"
  bottom: "conv4_7/expand/bn"
  top: "conv4_7/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_7/expand"
  type: "ReLU"
  bottom: "conv4_7/expand/bn"
  top: "conv4_7/expand/bn"
}
layer {
  name: "conv4_7/dwise"
  type: "Convolution"
  bottom: "conv4_7/expand/bn"
  top: "conv4_7/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 384
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4_7/dwise/bn"
  type: "BatchNorm"
  bottom: "conv4_7/dwise"
  top: "conv4_7/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_7/dwise/scale"
  type: "Scale"
  bottom: "conv4_7/dwise/bn"
  top: "conv4_7/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_7/dwise"
  type: "ReLU"
  bottom: "conv4_7/dwise/bn"
  top: "conv4_7/dwise/bn"
}
layer {
  name: "conv4_7/linear"
  type: "Convolution"
  bottom: "conv4_7/dwise/bn"
  top: "conv4_7/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_7/linear/bn"
  type: "BatchNorm"
  bottom: "conv4_7/linear"
  top: "conv4_7/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv4_7/linear/scale"
  type: "Scale"
  bottom: "conv4_7/linear/bn"
  top: "conv4_7/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1/expand"
  type: "Convolution"
  bottom: "conv4_7/linear/bn"
  top: "conv5_1/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 576
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/expand/bn"
  type: "BatchNorm"
  bottom: "conv5_1/expand"
  top: "conv5_1/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv5_1/expand/scale"
  type: "Scale"
  bottom: "conv5_1/expand/bn"
  top: "conv5_1/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1/expand"
  type: "ReLU"
  bottom: "conv5_1/expand/bn"
  top: "conv5_1/expand/bn"
}
layer {
  name: "conv5_1/dwise"
  type: "Convolution"
  bottom: "conv5_1/expand/bn"
  top: "conv5_1/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 576
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 576
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_1/dwise/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dwise"
  top: "conv5_1/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv5_1/dwise/scale"
  type: "Scale"
  bottom: "conv5_1/dwise/bn"
  top: "conv5_1/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1/dwise"
  type: "ReLU"
  bottom: "conv5_1/dwise/bn"
  top: "conv5_1/dwise/bn"
}
layer {
  name: "conv5_1/linear"
  type: "Convolution"
  bottom: "conv5_1/dwise/bn"
  top: "conv5_1/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/linear/bn"
  type: "BatchNorm"
  bottom: "conv5_1/linear"
  top: "conv5_1/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv5_1/linear/scale"
  type: "Scale"
  bottom: "conv5_1/linear/bn"
  top: "conv5_1/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "block_5_1"
  type: "Eltwise"
  bottom: "conv4_7/linear/bn"
  bottom: "conv5_1/linear/bn"
  top: "block_5_1"
}
layer {
  name: "conv5_2/expand"
  type: "Convolution"
  bottom: "block_5_1"
  top: "conv5_2/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 576
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/expand/bn"
  type: "BatchNorm"
  bottom: "conv5_2/expand"
  top: "conv5_2/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv5_2/expand/scale"
  type: "Scale"
  bottom: "conv5_2/expand/bn"
  top: "conv5_2/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2/expand"
  type: "ReLU"
  bottom: "conv5_2/expand/bn"
  top: "conv5_2/expand/bn"
}
layer {
  name: "conv5_2/dwise"
  type: "Convolution"
  bottom: "conv5_2/expand/bn"
  top: "conv5_2/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 576
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 576
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_2/dwise/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dwise"
  top: "conv5_2/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv5_2/dwise/scale"
  type: "Scale"
  bottom: "conv5_2/dwise/bn"
  top: "conv5_2/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2/dwise"
  type: "ReLU"
  bottom: "conv5_2/dwise/bn"
  top: "conv5_2/dwise/bn"
}
layer {
  name: "conv5_2/linear"
  type: "Convolution"
  bottom: "conv5_2/dwise/bn"
  top: "conv5_2/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/linear/bn"
  type: "BatchNorm"
  bottom: "conv5_2/linear"
  top: "conv5_2/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv5_2/linear/scale"
  type: "Scale"
  bottom: "conv5_2/linear/bn"
  top: "conv5_2/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "block_5_2"
  type: "Eltwise"
  bottom: "block_5_1"
  bottom: "conv5_2/linear/bn"
  top: "block_5_2"
}
layer {
  name: "conv5_3/expand"
  type: "Convolution"
  bottom: "block_5_2"
  top: "conv5_3/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 576
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/expand/bn"
  type: "BatchNorm"
  bottom: "conv5_3/expand"
  top: "conv5_3/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv5_3/expand/scale"
  type: "Scale"
  bottom: "conv5_3/expand/bn"
  top: "conv5_3/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3/expand"
  type: "ReLU"
  bottom: "conv5_3/expand/bn"
  top: "conv5_3/expand/bn"
}
layer {
  name: "conv5_3/dwise"
  type: "Convolution"
  bottom: "conv5_3/expand/bn"
  top: "conv5_3/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 576
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 576
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_3/dwise/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dwise"
  top: "conv5_3/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv5_3/dwise/scale"
  type: "Scale"
  bottom: "conv5_3/dwise/bn"
  top: "conv5_3/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3/dwise"
  type: "ReLU"
  bottom: "conv5_3/dwise/bn"
  top: "conv5_3/dwise/bn"
}
layer {
  name: "conv5_3/linear"
  type: "Convolution"
  bottom: "conv5_3/dwise/bn"
  top: "conv5_3/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 160
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/linear/bn"
  type: "BatchNorm"
  bottom: "conv5_3/linear"
  top: "conv5_3/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv5_3/linear/scale"
  type: "Scale"
  bottom: "conv5_3/linear/bn"
  top: "conv5_3/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1/expand"
  type: "Convolution"
  bottom: "conv5_3/linear/bn"
  top: "conv6_1/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 960
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_1/expand/bn"
  type: "BatchNorm"
  bottom: "conv6_1/expand"
  top: "conv6_1/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv6_1/expand/scale"
  type: "Scale"
  bottom: "conv6_1/expand/bn"
  top: "conv6_1/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6_1/expand"
  type: "ReLU"
  bottom: "conv6_1/expand/bn"
  top: "conv6_1/expand/bn"
}
layer {
  name: "conv6_1/dwise"
  type: "Convolution"
  bottom: "conv6_1/expand/bn"
  top: "conv6_1/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 960
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 960
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6_1/dwise/bn"
  type: "BatchNorm"
  bottom: "conv6_1/dwise"
  top: "conv6_1/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv6_1/dwise/scale"
  type: "Scale"
  bottom: "conv6_1/dwise/bn"
  top: "conv6_1/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6_1/dwise"
  type: "ReLU"
  bottom: "conv6_1/dwise/bn"
  top: "conv6_1/dwise/bn"
}
layer {
  name: "conv6_1/linear"
  type: "Convolution"
  bottom: "conv6_1/dwise/bn"
  top: "conv6_1/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 160
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_1/linear/bn"
  type: "BatchNorm"
  bottom: "conv6_1/linear"
  top: "conv6_1/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv6_1/linear/scale"
  type: "Scale"
  bottom: "conv6_1/linear/bn"
  top: "conv6_1/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "block_6_1"
  type: "Eltwise"
  bottom: "conv5_3/linear/bn"
  bottom: "conv6_1/linear/bn"
  top: "block_6_1"
}
layer {
  name: "conv6_2/expand"
  type: "Convolution"
  bottom: "block_6_1"
  top: "conv6_2/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 960
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_2/expand/bn"
  type: "BatchNorm"
  bottom: "conv6_2/expand"
  top: "conv6_2/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv6_2/expand/scale"
  type: "Scale"
  bottom: "conv6_2/expand/bn"
  top: "conv6_2/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6_2/expand"
  type: "ReLU"
  bottom: "conv6_2/expand/bn"
  top: "conv6_2/expand/bn"
}
layer {
  name: "conv6_2/dwise"
  type: "Convolution"
  bottom: "conv6_2/expand/bn"
  top: "conv6_2/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 960
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 960
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6_2/dwise/bn"
  type: "BatchNorm"
  bottom: "conv6_2/dwise"
  top: "conv6_2/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv6_2/dwise/scale"
  type: "Scale"
  bottom: "conv6_2/dwise/bn"
  top: "conv6_2/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6_2/dwise"
  type: "ReLU"
  bottom: "conv6_2/dwise/bn"
  top: "conv6_2/dwise/bn"
}
layer {
  name: "conv6_2/linear"
  type: "Convolution"
  bottom: "conv6_2/dwise/bn"
  top: "conv6_2/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 160
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_2/linear/bn"
  type: "BatchNorm"
  bottom: "conv6_2/linear"
  top: "conv6_2/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv6_2/linear/scale"
  type: "Scale"
  bottom: "conv6_2/linear/bn"
  top: "conv6_2/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "block_6_2"
  type: "Eltwise"
  bottom: "block_6_1"
  bottom: "conv6_2/linear/bn"
  top: "block_6_2"
}
layer {
  name: "conv6_3/expand"
  type: "Convolution"
  bottom: "block_6_2"
  top: "conv6_3/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 960
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_3/expand/bn"
  type: "BatchNorm"
  bottom: "conv6_3/expand"
  top: "conv6_3/expand/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv6_3/expand/scale"
  type: "Scale"
  bottom: "conv6_3/expand/bn"
  top: "conv6_3/expand/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6_3/expand"
  type: "ReLU"
  bottom: "conv6_3/expand/bn"
  top: "conv6_3/expand/bn"
}
layer {
  name: "conv6_3/dwise"
  type: "Convolution"
  bottom: "conv6_3/expand/bn"
  top: "conv6_3/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 960
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 960
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6_3/dwise/bn"
  type: "BatchNorm"
  bottom: "conv6_3/dwise"
  top: "conv6_3/dwise/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv6_3/dwise/scale"
  type: "Scale"
  bottom: "conv6_3/dwise/bn"
  top: "conv6_3/dwise/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6_3/dwise"
  type: "ReLU"
  bottom: "conv6_3/dwise/bn"
  top: "conv6_3/dwise/bn"
}
layer {
  name: "conv6_3/linear"
  type: "Convolution"
  bottom: "conv6_3/dwise/bn"
  top: "conv6_3/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 320
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_3/linear/bn"
  type: "BatchNorm"
  bottom: "conv6_3/linear"
  top: "conv6_3/linear/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv6_3/linear/scale"
  type: "Scale"
  bottom: "conv6_3/linear/bn"
  top: "conv6_3/linear/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_4"
  type: "Convolution"
  bottom: "conv6_3/linear/bn"
  top: "conv6_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1280
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_4/bn"
  type: "BatchNorm"
  bottom: "conv6_4"
  top: "conv6_4/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}
layer {
  name: "conv6_4/scale"
  type: "Scale"
  bottom: "conv6_4/bn"
  top: "conv6_4/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6_4"
  type: "ReLU"
  bottom: "conv6_4/bn"
  top: "conv6_4/bn"
}

################################################################################
## Hyper Net
################################################################################

layer {
  name: "downsample"
  type: "Pooling"
  bottom: "conv3_2/dwise/bn"
  top: "downsample"
  pooling_param { kernel_size: 3 stride: 2 pad: 0 pool: MAX }
}
layer {
    name: "upsample"
    type: "Deconvolution"
    bottom: "conv6_4/bn"
    top: "upsample"
    param { lr_mult: 0 decay_mult: 0}
    convolution_param {
        num_output: 1280 kernel_size: 4 pad: 1 stride: 2 group: 1280
        weight_filler: {type: "bilinear" } 
        bias_term: false
    }    
}
layer {
  name: "concat"
  bottom: "downsample"
  bottom: "conv4_7/dwise/bn"
  bottom: "upsample"
  top: "concat"
  type: "Concat"
  concat_param { axis: 1 }
}

layer {
  name: "convf_rpn"
  type: "Convolution"
  bottom: "concat"
  top: "convf_rpn"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0 }
  convolution_param {
    num_output: 128 kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "xavier" std: 0.1 }
    bias_filler { type: "constant" value: 0.1 }
  }
}
layer {
  name: "reluf_rpn"
  type: "ReLU"
  bottom: "convf_rpn"
  top: "convf_rpn"
}


layer {
  name: "convf_2"
  type: "Convolution"
  bottom: "concat"
  top: "convf_2"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0 }
  convolution_param {
    num_output: 384 kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "xavier" std: 0.1 }
    bias_filler { type: "constant" value: 0.1 }
  }
}
layer {
  name: "reluf_2"
  type: "ReLU"
  bottom: "convf_2"
  top: "convf_2"
}

layer {
  name: "concat_convf"
  bottom: "convf_rpn"
  bottom: "convf_2"
  top: "convf"
  type: "Concat"
  concat_param { axis: 1 }
}

################################################################################
## RPN
################################################################################

### RPN conv ###
layer {
  name: "rpn_conv1"
  type: "Convolution"
  bottom: "convf_rpn"
  top: "rpn_conv1"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0 }
  convolution_param {
    num_output: 384 kernel_size: 3 pad: 1 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "rpn_relu1"
  type: "ReLU"
  bottom: "rpn_conv1"
  top: "rpn_conv1"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn_conv1"
  top: "rpn_cls_score"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0 }
  convolution_param {
    num_output: 84   # 2(bg/fg) * 42(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn_conv1"
  top: "rpn_bbox_pred"
  param { lr_mult: 1.0 decay_mult: 1.0 }
  param { lr_mult: 2.0 decay_mult: 0 }
  convolution_param {
    num_output: 168   # 4 * 42(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
   bottom: "rpn_cls_score"
   top: "rpn_cls_score_reshape"
   name: "rpn_cls_score_reshape"
   type: "Reshape"
   reshape_param { shape { dim: 0 dim: 2 dim: -1 dim: 0 } }
}
layer {
  name: 'rpn-data'
  type: 'Python'
  bottom: 'rpn_cls_score'
  bottom: 'gt_boxes'
  bottom: 'im_info'
  bottom: 'data'
  top: 'rpn_labels'
  top: 'rpn_bbox_targets'
  top: 'rpn_bbox_inside_weights'
  top: 'rpn_bbox_outside_weights'
  include { phase: TRAIN }
  python_param {
    module: 'rpn.anchor_target_layer'
    layer: 'AnchorTargetLayer'
    param_str: "{'feat_stride': 16, 'ratios': [0.333, 0.5, 0.667, 1, 1.5, 2, 3], 'scales': [2, 3, 5, 9, 16, 32]}"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  propagate_down: 1
  propagate_down: 0
  top: "rpn_loss_cls"
  include { phase: TRAIN }
  loss_weight: 1
  loss_param { ignore_label: -1 normalize: true }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  include { phase: TRAIN }
  loss_weight: 1
  smooth_l1_loss_param { sigma: 3.0 }
}
  
################################################################################
## Proposal
################################################################################
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: 'rpn_cls_prob_reshape'
  type: 'Reshape'
  bottom: 'rpn_cls_prob'
  top: 'rpn_cls_prob_reshape'
  reshape_param { shape { dim: 0 dim: 84 dim: -1 dim: 0 } }
}
layer {
  name: 'proposal'
  type: 'Python'
  bottom: 'rpn_cls_prob_reshape'
  bottom: 'rpn_bbox_pred'
  bottom: 'im_info'
  top: 'rpn_rois'
  top: 'rpn_scores'
  include { phase: TRAIN }
  python_param {
    module: 'rpn.proposal_layer'
    layer: 'ProposalLayer'
    param_str: "{'feat_stride': 16, 'ratios': [0.333, 0.5, 0.667, 1, 1.5, 2, 3], 'scales': [2, 3, 5, 9, 16, 32]}"
  }
}

layer {
  name: 'proposal'
  type: 'Proposal'
  bottom: 'rpn_cls_prob_reshape'
  bottom: 'rpn_bbox_pred'
  bottom: 'im_info'
  top: 'rois'
  top: 'scores'
  include { phase: TEST }
   proposal_param {
    ratio:0.333 ratio: 0.5 ratio: 0.667 ratio: 1.0 ratio: 1.5 ratio: 2.0 ratio: 3.0
    scale:2 scale: 3 scale: 5 scale: 9 scale: 16 scale: 32
    base_size: 16
    feat_stride: 16
    pre_nms_topn: 12000
    post_nms_topn: 300
    nms_thresh: 0.7
    min_size: 16
  }
}

layer {
  name: 'mute_rpn_scores'
  bottom: 'rpn_scores'
  type: 'Silence'
  include { phase: TRAIN }
}
layer {
  name: 'roi-data'
  type: 'Python'
  bottom: 'rpn_rois'
  bottom: 'gt_boxes'
  top: 'rois'
  top: 'labels'
  top: 'bbox_targets'
  top: 'bbox_inside_weights'
  top: 'bbox_outside_weights'
  include { phase: TRAIN }	
  python_param {
    module: 'rpn.proposal_target_layer'
    layer: 'ProposalTargetLayer'
    param_str: "'num_classes': 21"
  }
}

################################################################################
## RCNN
################################################################################
layer {
  name: "roi_pool_conv5"
  type: "ROIPooling"
  bottom: "convf"
  bottom: "rois"
  top: "roi_pool_conv5"
  roi_pooling_param {
    pooled_w: 6
    pooled_h: 6
    spatial_scale: 0.0625 # 1/16
  }
}
layer {
  name: "fc6_"
  type: "InnerProduct"
  bottom: "roi_pool_conv5"
  top: "fc6_"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "fc6_/bn"
  type: "BatchNorm"
  bottom: "fc6_"
  top: "fc6_"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "fc6_/scale"
  type: "Scale"
  bottom: "fc6_"
  top: "fc6_"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "fc6_/dropout"
  type: "Dropout"
  bottom: "fc6_"
  top: "fc6_"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "fc6_/relu"
  type: "ReLU"
  bottom: "fc6_"
  top: "fc6_"
}
layer {
  name: "fc7_"
  type: "InnerProduct"
  bottom: "fc6_"
  top: "fc7_"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "fc7_/bn"
  type: "BatchNorm"
  bottom: "fc7_"
  top: "fc7_"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "fc7_/scale"
  type: "Scale"
  bottom: "fc7_"
  top: "fc7_"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "fc7_/dropout"
  type: "Dropout"
  bottom: "fc7_"
  top: "fc7_"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "fc7_/relu"
  type: "ReLU"
  bottom: "fc7_"
  top: "fc7_"
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7_"
  top: "cls_score"
  param { lr_mult: 1.0 }
  param { lr_mult: 2.0 }
  inner_product_param {
    num_output: 21
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7_"
  top: "bbox_pred"
  param { lr_mult: 1.0 }
  param { lr_mult: 2.0 }
  inner_product_param {
    num_output: 84
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "cls_prob"
  type: "Softmax"
  bottom: "cls_score"
  top: "cls_prob"
}
